{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Required Libraries Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import opencv\n",
    "import cv2 \n",
    "\n",
    "# Import uuid\n",
    "import uuid\n",
    "\n",
    "# Import Operating System\n",
    "import os\n",
    "\n",
    "# Import time\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/elif/Documents/my_virtual_env/TFODCourse/BitirmeTezi\n"
     ]
    }
   ],
   "source": [
    "#dizin kontrolÃ¼\n",
    "!pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "CUSTOM_MODEL_NAME = 'my_ssd_mobnet' \n",
    "PRETRAINED_MODEL_NAME = 'ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8'\n",
    "PRETRAINED_MODEL_URL = 'http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz'\n",
    "TF_RECORD_SCRIPT_NAME = 'generate_tfrecord.py'\n",
    "LABEL_MAP_NAME = 'label_map.pbtxt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = {\n",
    "    'WORKSPACE_PATH': os.path.join('Tensorflow', 'workspace'),\n",
    "    'SCRIPTS_PATH': os.path.join('Tensorflow','scripts'),\n",
    "    'APIMODEL_PATH': os.path.join('Tensorflow','models'),\n",
    "    'ANNOTATION_PATH': os.path.join('Tensorflow', 'workspace','annotations'),\n",
    "    'IMAGE_PATH': os.path.join('Tensorflow', 'workspace','images'),\n",
    "    'MODEL_PATH': os.path.join('Tensorflow', 'workspace','models'),\n",
    "    'PRETRAINED_MODEL_PATH': os.path.join('Tensorflow', 'workspace','pre-trained-models'),\n",
    "    'CHECKPOINT_PATH': os.path.join('Tensorflow', 'workspace','models',CUSTOM_MODEL_NAME), \n",
    "    'OUTPUT_PATH': os.path.join('Tensorflow', 'workspace','models',CUSTOM_MODEL_NAME, 'export'), \n",
    "    'TFJS_PATH':os.path.join('Tensorflow', 'workspace','models',CUSTOM_MODEL_NAME, 'tfjsexport'), \n",
    "    'TFLITE_PATH':os.path.join('Tensorflow', 'workspace','models',CUSTOM_MODEL_NAME, 'tfliteexport'), \n",
    "    'PROTOC_PATH':os.path.join('Tensorflow','protoc')\n",
    " }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = {\n",
    "    'PIPELINE_CONFIG':os.path.join('Tensorflow', 'workspace','models', CUSTOM_MODEL_NAME, 'pipeline.config'),\n",
    "    'TF_RECORD_SCRIPT': os.path.join(paths['SCRIPTS_PATH'], TF_RECORD_SCRIPT_NAME), \n",
    "    'LABELMAP': os.path.join(paths['ANNOTATION_PATH'], LABEL_MAP_NAME)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for path in paths.values():\n",
    "    if not os.path.exists(path):\n",
    "        if os.name == 'posix':\n",
    "            !mkdir -p {path}\n",
    "        if os.name == 'nt':\n",
    "            !mkdir {path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tensorflow/workspace/models/my_ssd_mobnet'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paths['CHECKPOINT_PATH']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/elif/Documents/my_virtual_env/TFODCourse/BitirmeTezi\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download Model : ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection')):\n",
    "    !git clone https://github.com/tensorflow/models {paths['APIMODEL_PATH']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: tensorflow-gpu==1.14 in /home/elif/.local/lib/python3.6/site-packages (1.14.0)\n",
      "Requirement already satisfied: protobuf>=3.6.1 in /home/elif/.local/lib/python3.6/site-packages (from tensorflow-gpu==1.14) (3.19.3)\n",
      "Collecting tensorflow-estimator<1.15.0rc0,>=1.14.0rc0\n",
      "  Using cached tensorflow_estimator-1.14.0-py2.py3-none-any.whl (488 kB)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in /home/elif/.local/lib/python3.6/site-packages (from tensorflow-gpu==1.14) (1.12.1)\n",
      "Requirement already satisfied: numpy<2.0,>=1.14.5 in /home/elif/.local/lib/python3.6/site-packages (from tensorflow-gpu==1.14) (1.19.5)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /home/elif/.local/lib/python3.6/site-packages (from tensorflow-gpu==1.14) (1.1.2)\n",
      "Requirement already satisfied: astor>=0.6.0 in /home/elif/.local/lib/python3.6/site-packages (from tensorflow-gpu==1.14) (0.8.1)\n",
      "Collecting tensorboard<1.15.0,>=1.14.0\n",
      "  Using cached tensorboard-1.14.0-py3-none-any.whl (3.1 MB)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/elif/.local/lib/python3.6/site-packages (from tensorflow-gpu==1.14) (1.1.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.6 in /home/elif/.local/lib/python3.6/site-packages (from tensorflow-gpu==1.14) (0.2.0)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in /home/elif/.local/lib/python3.6/site-packages (from tensorflow-gpu==1.14) (1.0.8)\n",
      "Requirement already satisfied: gast>=0.2.0 in /home/elif/.local/lib/python3.6/site-packages (from tensorflow-gpu==1.14) (0.4.0)\n",
      "Requirement already satisfied: wheel>=0.26 in /home/elif/.local/lib/python3.6/site-packages (from tensorflow-gpu==1.14) (0.37.0)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /home/elif/.local/lib/python3.6/site-packages (from tensorflow-gpu==1.14) (1.41.0)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in /home/elif/.local/lib/python3.6/site-packages (from tensorflow-gpu==1.14) (0.12.0)\n",
      "Requirement already satisfied: six>=1.10.0 in /home/elif/.local/lib/python3.6/site-packages (from tensorflow-gpu==1.14) (1.15.0)\n",
      "Requirement already satisfied: h5py in /home/elif/.local/lib/python3.6/site-packages (from keras-applications>=1.0.6->tensorflow-gpu==1.14) (3.1.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /home/elif/.local/lib/python3.6/site-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow-gpu==1.14) (2.0.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/elif/.local/lib/python3.6/site-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow-gpu==1.14) (3.3.4)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /home/elif/.local/lib/python3.6/site-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow-gpu==1.14) (58.1.0)\n",
      "Requirement already satisfied: importlib-metadata in /home/elif/.local/lib/python3.6/site-packages (from markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow-gpu==1.14) (4.8.1)\n",
      "Requirement already satisfied: dataclasses in /home/elif/.local/lib/python3.6/site-packages (from werkzeug>=0.11.15->tensorboard<1.15.0,>=1.14.0->tensorflow-gpu==1.14) (0.8)\n",
      "Requirement already satisfied: cached-property in /home/elif/.local/lib/python3.6/site-packages (from h5py->keras-applications>=1.0.6->tensorflow-gpu==1.14) (1.5.2)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/elif/.local/lib/python3.6/site-packages (from importlib-metadata->markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow-gpu==1.14) (3.5.1)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /home/elif/.local/lib/python3.6/site-packages (from importlib-metadata->markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow-gpu==1.14) (3.7.4.3)\n",
      "Installing collected packages: tensorflow-estimator, tensorboard\n",
      "  Attempting uninstall: tensorflow-estimator\n",
      "    Found existing installation: tensorflow-estimator 2.6.0\n",
      "    Uninstalling tensorflow-estimator-2.6.0:\n",
      "      Successfully uninstalled tensorflow-estimator-2.6.0\n",
      "  Attempting uninstall: tensorboard\n",
      "    Found existing installation: tensorboard 2.6.0\n",
      "    Uninstalling tensorboard-2.6.0:\n",
      "      Successfully uninstalled tensorboard-2.6.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorflow 2.6.2 requires tensorboard<2.7,>=2.6.0, but you have tensorboard 1.14.0 which is incompatible.\n",
      "tensorflow 2.6.2 requires tensorflow-estimator<2.7,>=2.6.0, but you have tensorflow-estimator 1.14.0 which is incompatible.\u001b[0m\n",
      "Successfully installed tensorboard-1.14.0 tensorflow-estimator-1.14.0\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow-gpu==1.14 --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: protobuf 3.19.3\n",
      "Uninstalling protobuf-3.19.3:\n",
      "  Successfully uninstalled protobuf-3.19.3\n",
      "Found existing installation: matplotlib 3.2.0\n",
      "Uninstalling matplotlib-3.2.0:\n",
      "  Successfully uninstalled matplotlib-3.2.0\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: protobuf in /usr/lib/python3/dist-packages (3.0.0)\n",
      "Collecting matplotlib==3.2\n",
      "  Using cached matplotlib-3.2.0-cp36-cp36m-manylinux1_x86_64.whl (12.4 MB)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /home/elif/.local/lib/python3.6/site-packages (from matplotlib==3.2) (2.8.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/elif/.local/lib/python3.6/site-packages (from matplotlib==3.2) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/elif/.local/lib/python3.6/site-packages (from matplotlib==3.2) (1.3.1)\n",
      "Requirement already satisfied: numpy>=1.11 in /home/elif/.local/lib/python3.6/site-packages (from matplotlib==3.2) (1.19.5)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /home/elif/.local/lib/python3.6/site-packages (from matplotlib==3.2) (2.4.7)\n",
      "Requirement already satisfied: six in /home/elif/.local/lib/python3.6/site-packages (from cycler>=0.10->matplotlib==3.2) (1.15.0)\n",
      "Installing collected packages: matplotlib\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tf-models-official 2.6.1 requires opencv-python-headless, which is not installed.\u001b[0m\n",
      "Successfully installed matplotlib-3.2.0\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall protobuf matplotlib -y\n",
    "!pip install protobuf matplotlib==3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E: Could not open lock file /var/lib/dpkg/lock-frontend - open (13: Permission denied)\n",
      "E: Unable to acquire the dpkg frontend lock (/var/lib/dpkg/lock-frontend), are you root?\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Processing /home/elif/Documents/my_virtual_env/TFODCourse/BitirmeTezi/Tensorflow/models/research\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: avro-python3 in /home/elif/.local/lib/python3.6/site-packages (from object-detection==0.1) (1.10.2)\n",
      "Requirement already satisfied: apache-beam in /home/elif/.local/lib/python3.6/site-packages (from object-detection==0.1) (2.35.0)\n",
      "Requirement already satisfied: pillow in /home/elif/.local/lib/python3.6/site-packages (from object-detection==0.1) (8.3.2)\n",
      "Requirement already satisfied: lxml in /home/elif/.local/lib/python3.6/site-packages (from object-detection==0.1) (4.7.1)\n",
      "Requirement already satisfied: matplotlib in /home/elif/.local/lib/python3.6/site-packages (from object-detection==0.1) (3.2.0)\n",
      "Requirement already satisfied: Cython in /home/elif/.local/lib/python3.6/site-packages (from object-detection==0.1) (0.29.24)\n",
      "Requirement already satisfied: contextlib2 in /home/elif/.local/lib/python3.6/site-packages (from object-detection==0.1) (21.6.0)\n",
      "Requirement already satisfied: tf-slim in /home/elif/.local/lib/python3.6/site-packages (from object-detection==0.1) (1.1.0)\n",
      "Requirement already satisfied: six in /home/elif/.local/lib/python3.6/site-packages (from object-detection==0.1) (1.15.0)\n",
      "Requirement already satisfied: pycocotools in /home/elif/.local/lib/python3.6/site-packages (from object-detection==0.1) (2.0.4)\n",
      "Requirement already satisfied: lvis in /home/elif/.local/lib/python3.6/site-packages (from object-detection==0.1) (0.5.3)\n",
      "Requirement already satisfied: scipy in /home/elif/.local/lib/python3.6/site-packages (from object-detection==0.1) (1.5.4)\n",
      "Requirement already satisfied: pandas in /home/elif/.local/lib/python3.6/site-packages (from object-detection==0.1) (1.1.5)\n",
      "Requirement already satisfied: tf-models-official>=2.5.1 in /home/elif/.local/lib/python3.6/site-packages (from object-detection==0.1) (2.6.1)\n",
      "Requirement already satisfied: tensorflow_io in /home/elif/.local/lib/python3.6/site-packages (from object-detection==0.1) (0.21.0)\n",
      "Requirement already satisfied: keras in /home/elif/.local/lib/python3.6/site-packages (from object-detection==0.1) (2.6.0)\n",
      "Requirement already satisfied: dataclasses in /home/elif/.local/lib/python3.6/site-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.8)\n",
      "Requirement already satisfied: oauth2client in /home/elif/.local/lib/python3.6/site-packages (from tf-models-official>=2.5.1->object-detection==0.1) (4.1.3)\n",
      "Requirement already satisfied: tensorflow-model-optimization>=0.4.1 in /home/elif/.local/lib/python3.6/site-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.7.0)\n",
      "Requirement already satisfied: sentencepiece in /home/elif/.local/lib/python3.6/site-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.1.96)\n",
      "Collecting opencv-python-headless\n",
      "  Using cached opencv_python_headless-4.5.5.62-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (47.7 MB)\n",
      "Requirement already satisfied: numpy>=1.15.4 in /home/elif/.local/lib/python3.6/site-packages (from tf-models-official>=2.5.1->object-detection==0.1) (1.19.5)\n",
      "Requirement already satisfied: tensorflow-datasets in /home/elif/.local/lib/python3.6/site-packages (from tf-models-official>=2.5.1->object-detection==0.1) (4.5.0)\n",
      "Requirement already satisfied: gin-config in /home/elif/.local/lib/python3.6/site-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.5.0)\n",
      "Requirement already satisfied: kaggle>=1.3.9 in /home/elif/.local/lib/python3.6/site-packages (from tf-models-official>=2.5.1->object-detection==0.1) (1.5.12)\n",
      "Requirement already satisfied: tensorflow-addons in /home/elif/.local/lib/python3.6/site-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.14.0)\n",
      "Requirement already satisfied: psutil>=5.4.3 in /home/elif/.local/lib/python3.6/site-packages (from tf-models-official>=2.5.1->object-detection==0.1) (5.8.0)\n",
      "Requirement already satisfied: google-api-python-client>=1.6.7 in /home/elif/.local/lib/python3.6/site-packages (from tf-models-official>=2.5.1->object-detection==0.1) (2.36.0)\n",
      "Requirement already satisfied: tensorflow>=2.6.0 in /home/elif/.local/lib/python3.6/site-packages (from tf-models-official>=2.5.1->object-detection==0.1) (2.6.2)\n",
      "Requirement already satisfied: tensorflow-hub>=0.6.0 in /home/elif/.local/lib/python3.6/site-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.12.0)\n",
      "Requirement already satisfied: seqeval in /home/elif/.local/lib/python3.6/site-packages (from tf-models-official>=2.5.1->object-detection==0.1) (1.2.2)\n",
      "Requirement already satisfied: tensorflow-text>=2.6.0 in /home/elif/.local/lib/python3.6/site-packages (from tf-models-official>=2.5.1->object-detection==0.1) (2.6.0)\n",
      "Requirement already satisfied: sacrebleu in /home/elif/.local/lib/python3.6/site-packages (from tf-models-official>=2.5.1->object-detection==0.1) (2.0.0)\n",
      "Requirement already satisfied: py-cpuinfo>=3.3.0 in /home/elif/.local/lib/python3.6/site-packages (from tf-models-official>=2.5.1->object-detection==0.1) (8.0.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/elif/.local/lib/python3.6/site-packages (from tf-models-official>=2.5.1->object-detection==0.1) (5.4.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in /home/elif/.local/lib/python3.6/site-packages (from pandas->object-detection==0.1) (2021.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /home/elif/.local/lib/python3.6/site-packages (from pandas->object-detection==0.1) (2.8.2)\n",
      "Requirement already satisfied: absl-py>=0.2.2 in /home/elif/.local/lib/python3.6/site-packages (from tf-slim->object-detection==0.1) (0.12.0)\n",
      "Requirement already satisfied: grpcio<2,>=1.29.0 in /home/elif/.local/lib/python3.6/site-packages (from apache-beam->object-detection==0.1) (1.41.0)\n",
      "Requirement already satisfied: pydot<2,>=1.2.0 in /home/elif/.local/lib/python3.6/site-packages (from apache-beam->object-detection==0.1) (1.4.2)\n",
      "Requirement already satisfied: pyarrow<7.0.0,>=0.15.1 in /home/elif/.local/lib/python3.6/site-packages (from apache-beam->object-detection==0.1) (6.0.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.24.0 in /home/elif/.local/lib/python3.6/site-packages (from apache-beam->object-detection==0.1) (2.25.1)\n",
      "Requirement already satisfied: fastavro<2,>=0.21.4 in /home/elif/.local/lib/python3.6/site-packages (from apache-beam->object-detection==0.1) (1.4.7)\n",
      "Requirement already satisfied: hdfs<3.0.0,>=2.1.0 in /home/elif/.local/lib/python3.6/site-packages (from apache-beam->object-detection==0.1) (2.6.0)\n",
      "Requirement already satisfied: typing-extensions<4,>=3.7.0 in /home/elif/.local/lib/python3.6/site-packages (from apache-beam->object-detection==0.1) (3.7.4.3)\n",
      "Collecting protobuf<4,>=3.12.2\n",
      "  Using cached protobuf-3.19.3-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
      "Requirement already satisfied: pymongo<4.0.0,>=3.8.0 in /home/elif/.local/lib/python3.6/site-packages (from apache-beam->object-detection==0.1) (3.12.3)\n",
      "Requirement already satisfied: proto-plus<2,>=1.7.1 in /home/elif/.local/lib/python3.6/site-packages (from apache-beam->object-detection==0.1) (1.19.9)\n",
      "Requirement already satisfied: httplib2<0.20.0,>=0.8 in /home/elif/.local/lib/python3.6/site-packages (from apache-beam->object-detection==0.1) (0.19.1)\n",
      "Requirement already satisfied: dill<0.3.2,>=0.3.1.1 in /home/elif/.local/lib/python3.6/site-packages (from apache-beam->object-detection==0.1) (0.3.1.1)\n",
      "Requirement already satisfied: orjson<4.0 in /home/elif/.local/lib/python3.6/site-packages (from apache-beam->object-detection==0.1) (3.6.1)\n",
      "Requirement already satisfied: crcmod<2.0,>=1.7 in /home/elif/.local/lib/python3.6/site-packages (from apache-beam->object-detection==0.1) (1.7)\n",
      "Requirement already satisfied: cycler>=0.10.0 in /home/elif/.local/lib/python3.6/site-packages (from lvis->object-detection==0.1) (0.10.0)\n",
      "Requirement already satisfied: opencv-python>=4.1.0.25 in /home/elif/.local/lib/python3.6/site-packages (from lvis->object-detection==0.1) (4.5.5.62)\n",
      "Requirement already satisfied: pyparsing>=2.4.0 in /home/elif/.local/lib/python3.6/site-packages (from lvis->object-detection==0.1) (2.4.7)\n",
      "Requirement already satisfied: kiwisolver>=1.1.0 in /home/elif/.local/lib/python3.6/site-packages (from lvis->object-detection==0.1) (1.3.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem==0.21.0 in /home/elif/.local/lib/python3.6/site-packages (from tensorflow_io->object-detection==0.1) (0.21.0)\n",
      "Requirement already satisfied: google-auth<3.0.0dev,>=1.16.0 in /home/elif/.local/lib/python3.6/site-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (1.35.0)\n",
      "Requirement already satisfied: uritemplate<5,>=3.0.1 in /home/elif/.local/lib/python3.6/site-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (4.1.1)\n",
      "Requirement already satisfied: google-auth-httplib2>=0.1.0 in /home/elif/.local/lib/python3.6/site-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.1.0)\n",
      "Requirement already satisfied: google-api-core<3.0.0dev,>=1.21.0 in /home/elif/.local/lib/python3.6/site-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.4.0)\n",
      "Requirement already satisfied: docopt in /home/elif/.local/lib/python3.6/site-packages (from hdfs<3.0.0,>=2.1.0->apache-beam->object-detection==0.1) (0.6.2)\n",
      "Requirement already satisfied: tqdm in /home/elif/.local/lib/python3.6/site-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (4.61.2)\n",
      "Requirement already satisfied: urllib3 in /home/elif/.local/lib/python3.6/site-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (1.26.6)\n",
      "Requirement already satisfied: python-slugify in /home/elif/.local/lib/python3.6/site-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (5.0.2)\n",
      "Requirement already satisfied: certifi in /home/elif/.local/lib/python3.6/site-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (2021.5.30)\n",
      "Requirement already satisfied: rsa>=3.1.4 in /home/elif/.local/lib/python3.6/site-packages (from oauth2client->tf-models-official>=2.5.1->object-detection==0.1) (4.8)\n",
      "Requirement already satisfied: pyasn1>=0.1.7 in /home/elif/.local/lib/python3.6/site-packages (from oauth2client->tf-models-official>=2.5.1->object-detection==0.1) (0.4.8)\n",
      "Requirement already satisfied: pyasn1-modules>=0.0.5 in /home/elif/.local/lib/python3.6/site-packages (from oauth2client->tf-models-official>=2.5.1->object-detection==0.1) (0.2.8)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /home/elif/.local/lib/python3.6/site-packages (from requests<3.0.0,>=2.24.0->apache-beam->object-detection==0.1) (4.0.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /home/elif/.local/lib/python3.6/site-packages (from requests<3.0.0,>=2.24.0->apache-beam->object-detection==0.1) (2.10)\n",
      "Requirement already satisfied: flatbuffers~=1.12.0 in /home/elif/.local/lib/python3.6/site-packages (from tensorflow>=2.6.0->tf-models-official>=2.5.1->object-detection==0.1) (1.12)\n",
      "Requirement already satisfied: google-pasta~=0.2 in /home/elif/.local/lib/python3.6/site-packages (from tensorflow>=2.6.0->tf-models-official>=2.5.1->object-detection==0.1) (0.2.0)\n",
      "Requirement already satisfied: termcolor~=1.1.0 in /home/elif/.local/lib/python3.6/site-packages (from tensorflow>=2.6.0->tf-models-official>=2.5.1->object-detection==0.1) (1.1.0)\n",
      "Requirement already satisfied: wrapt~=1.12.1 in /home/elif/.local/lib/python3.6/site-packages (from tensorflow>=2.6.0->tf-models-official>=2.5.1->object-detection==0.1) (1.12.1)\n",
      "Requirement already satisfied: keras-preprocessing~=1.1.2 in /home/elif/.local/lib/python3.6/site-packages (from tensorflow>=2.6.0->tf-models-official>=2.5.1->object-detection==0.1) (1.1.2)\n",
      "Requirement already satisfied: h5py~=3.1.0 in /home/elif/.local/lib/python3.6/site-packages (from tensorflow>=2.6.0->tf-models-official>=2.5.1->object-detection==0.1) (3.1.0)\n",
      "Requirement already satisfied: clang~=5.0 in /home/elif/.local/lib/python3.6/site-packages (from tensorflow>=2.6.0->tf-models-official>=2.5.1->object-detection==0.1) (5.0)\n",
      "Requirement already satisfied: gast==0.4.0 in /home/elif/.local/lib/python3.6/site-packages (from tensorflow>=2.6.0->tf-models-official>=2.5.1->object-detection==0.1) (0.4.0)\n",
      "Requirement already satisfied: astunparse~=1.6.3 in /home/elif/.local/lib/python3.6/site-packages (from tensorflow>=2.6.0->tf-models-official>=2.5.1->object-detection==0.1) (1.6.3)\n",
      "Collecting tensorflow-estimator<2.7,>=2.6.0\n",
      "  Using cached tensorflow_estimator-2.6.0-py2.py3-none-any.whl (462 kB)\n",
      "Requirement already satisfied: opt-einsum~=3.3.0 in /home/elif/.local/lib/python3.6/site-packages (from tensorflow>=2.6.0->tf-models-official>=2.5.1->object-detection==0.1) (3.3.0)\n",
      "Requirement already satisfied: wheel~=0.35 in /home/elif/.local/lib/python3.6/site-packages (from tensorflow>=2.6.0->tf-models-official>=2.5.1->object-detection==0.1) (0.37.0)\n",
      "Collecting tensorboard<2.7,>=2.6.0\n",
      "  Using cached tensorboard-2.6.0-py3-none-any.whl (5.6 MB)\n",
      "Requirement already satisfied: dm-tree~=0.1.1 in /home/elif/.local/lib/python3.6/site-packages (from tensorflow-model-optimization>=0.4.1->tf-models-official>=2.5.1->object-detection==0.1) (0.1.6)\n",
      "Requirement already satisfied: portalocker in /home/elif/.local/lib/python3.6/site-packages (from sacrebleu->tf-models-official>=2.5.1->object-detection==0.1) (2.3.2)\n",
      "Requirement already satisfied: colorama in /usr/lib/python3/dist-packages (from sacrebleu->tf-models-official>=2.5.1->object-detection==0.1) (0.3.7)\n",
      "Requirement already satisfied: regex in /home/elif/.local/lib/python3.6/site-packages (from sacrebleu->tf-models-official>=2.5.1->object-detection==0.1) (2021.7.6)\n",
      "Requirement already satisfied: tabulate>=0.8.9 in /home/elif/.local/lib/python3.6/site-packages (from sacrebleu->tf-models-official>=2.5.1->object-detection==0.1) (0.8.9)\n",
      "Requirement already satisfied: scikit-learn>=0.21.3 in /home/elif/.local/lib/python3.6/site-packages (from seqeval->tf-models-official>=2.5.1->object-detection==0.1) (0.24.2)\n",
      "Requirement already satisfied: typeguard>=2.7 in /home/elif/.local/lib/python3.6/site-packages (from tensorflow-addons->tf-models-official>=2.5.1->object-detection==0.1) (2.13.3)\n",
      "Requirement already satisfied: importlib-resources in /home/elif/.local/lib/python3.6/site-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (5.2.2)\n",
      "Requirement already satisfied: tensorflow-metadata in /home/elif/.local/lib/python3.6/site-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (1.2.0)\n",
      "Requirement already satisfied: promise in /home/elif/.local/lib/python3.6/site-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (2.3)\n",
      "Requirement already satisfied: setuptools>=40.3.0 in /home/elif/.local/lib/python3.6/site-packages (from google-api-core<3.0.0dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (58.1.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.52.0 in /home/elif/.local/lib/python3.6/site-packages (from google-api-core<3.0.0dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (1.54.0)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /home/elif/.local/lib/python3.6/site-packages (from google-auth<3.0.0dev,>=1.16.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (4.2.4)\n",
      "Requirement already satisfied: cached-property in /home/elif/.local/lib/python3.6/site-packages (from h5py~=3.1.0->tensorflow>=2.6.0->tf-models-official>=2.5.1->object-detection==0.1) (1.5.2)\n",
      "Requirement already satisfied: joblib>=0.11 in /home/elif/.local/lib/python3.6/site-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official>=2.5.1->object-detection==0.1) (1.0.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/elif/.local/lib/python3.6/site-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official>=2.5.1->object-detection==0.1) (2.1.0)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /home/elif/.local/lib/python3.6/site-packages (from tensorboard<2.7,>=2.6.0->tensorflow>=2.6.0->tf-models-official>=2.5.1->object-detection==0.1) (1.8.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /home/elif/.local/lib/python3.6/site-packages (from tensorboard<2.7,>=2.6.0->tensorflow>=2.6.0->tf-models-official>=2.5.1->object-detection==0.1) (0.6.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /home/elif/.local/lib/python3.6/site-packages (from tensorboard<2.7,>=2.6.0->tensorflow>=2.6.0->tf-models-official>=2.5.1->object-detection==0.1) (0.4.6)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /home/elif/.local/lib/python3.6/site-packages (from tensorboard<2.7,>=2.6.0->tensorflow>=2.6.0->tf-models-official>=2.5.1->object-detection==0.1) (2.0.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/elif/.local/lib/python3.6/site-packages (from tensorboard<2.7,>=2.6.0->tensorflow>=2.6.0->tf-models-official>=2.5.1->object-detection==0.1) (3.3.4)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /home/elif/.local/lib/python3.6/site-packages (from importlib-resources->tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (3.5.1)\n",
      "Requirement already satisfied: text-unidecode>=1.3 in /home/elif/.local/lib/python3.6/site-packages (from python-slugify->kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (1.3)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/elif/.local/lib/python3.6/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.7,>=2.6.0->tensorflow>=2.6.0->tf-models-official>=2.5.1->object-detection==0.1) (1.3.0)\n",
      "Requirement already satisfied: importlib-metadata in /home/elif/.local/lib/python3.6/site-packages (from markdown>=2.6.8->tensorboard<2.7,>=2.6.0->tensorflow>=2.6.0->tf-models-official>=2.5.1->object-detection==0.1) (4.8.1)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /home/elif/.local/lib/python3.6/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.7,>=2.6.0->tensorflow>=2.6.0->tf-models-official>=2.5.1->object-detection==0.1) (3.1.1)\n",
      "Building wheels for collected packages: object-detection\n",
      "  Building wheel for object-detection (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for object-detection: filename=object_detection-0.1-py3-none-any.whl size=1684828 sha256=4b7049249d2412653e278e467fa50c3b2d77fdee150bf03eea74643b0c87f839\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-rwxxfhg6/wheels/fe/a1/a6/1b6db92aadabe6bbd6e83c8570d4f07537bb88364a3595b21c\n",
      "Successfully built object-detection\n",
      "Installing collected packages: protobuf, tensorflow-estimator, tensorboard, opencv-python-headless, object-detection\n",
      "  Attempting uninstall: tensorflow-estimator\n",
      "    Found existing installation: tensorflow-estimator 1.14.0\n",
      "    Uninstalling tensorflow-estimator-1.14.0:\n",
      "      Successfully uninstalled tensorflow-estimator-1.14.0\n",
      "  Attempting uninstall: tensorboard\n",
      "    Found existing installation: tensorboard 1.14.0\n",
      "    Uninstalling tensorboard-1.14.0:\n",
      "      Successfully uninstalled tensorboard-1.14.0\n",
      "  Attempting uninstall: object-detection\n",
      "    Found existing installation: object-detection 0.1\n",
      "    Uninstalling object-detection-0.1:\n",
      "      Successfully uninstalled object-detection-0.1\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorflow-gpu 1.14.0 requires tensorboard<1.15.0,>=1.14.0, but you have tensorboard 2.6.0 which is incompatible.\n",
      "tensorflow-gpu 1.14.0 requires tensorflow-estimator<1.15.0rc0,>=1.14.0rc0, but you have tensorflow-estimator 2.6.0 which is incompatible.\u001b[0m\n",
      "Successfully installed object-detection-0.1 opencv-python-headless-4.5.5.62 protobuf-3.19.3 tensorboard-2.6.0 tensorflow-estimator-2.6.0\n"
     ]
    }
   ],
   "source": [
    "# Install Tensorflow Object Detection \n",
    "\n",
    "#linux ve mac iÃ§in posix\n",
    "if os.name=='posix':  \n",
    "    !apt-get install protobuf-compiler\n",
    "    !cd Tensorflow/models/research && protoc object_detection/protos/*.proto --python_out=. && cp object_detection/packages/tf2/setup.py . && python3 -m pip install . \n",
    "#windows iÃ§in nt    \n",
    "if os.name=='nt':\n",
    "    url=\"https://github.com/protocolbuffers/protobuf/releases/download/v3.15.6/protoc-3.15.6-win64.zip\"\n",
    "    wget.download(url)\n",
    "    !move protoc-3.15.6-win64.zip {paths['PROTOC_PATH']}\n",
    "    !cd {paths['PROTOC_PATH']} && tar -xf protoc-3.15.6-win64.zip\n",
    "    os.environ['PATH'] += os.pathsep + os.path.abspath(os.path.join(paths['PROTOC_PATH'], 'bin'))   \n",
    "    !cd Tensorflow/models/research && protoc object_detection/protos/*.proto --python_out=. && copy object_detection\\\\packages\\\\tf2\\\\setup.py setup.py && python setup.py build && python setup.py install\n",
    "    !cd Tensorflow/models/research/slim && pip install -e . "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-01-28 19:33:20.510386: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-01-28 19:33:20.510462: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2022-01-28 19:33:44.129091: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-28 19:33:44.129636: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-01-28 19:33:44.129741: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2022-01-28 19:33:44.129820: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2022-01-28 19:33:44.129896: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory\n",
      "2022-01-28 19:33:44.129971: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory\n",
      "2022-01-28 19:33:44.130047: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2022-01-28 19:33:44.130124: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2022-01-28 19:33:44.130193: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2022-01-28 19:33:44.130209: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1835] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "Running tests under Python 3.6.9: /usr/bin/python3\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_deepmac\n",
      "2022-01-28 19:33:44.190492: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/home/elif/.local/lib/python3.6/site-packages/object_detection/builders/model_builder.py:1100: DeprecationWarning: The 'warn' function is deprecated, use 'warning' instead\n",
      "  logging.warn(('Building experimental DeepMAC meta-arch.'\n",
      "W0128 19:33:44.607621 140105121920832 model_builder.py:1100] Building experimental DeepMAC meta-arch. Some features may be omitted.\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_deepmac): 0.7s\n",
      "I0128 19:33:44.830734 140105121920832 test_util.py:2189] time(__main__.ModelBuilderTF2Test.test_create_center_net_deepmac): 0.7s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_center_net_deepmac\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)): 0.62s\n",
      "I0128 19:33:45.446483 140105121920832 test_util.py:2189] time(__main__.ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)): 0.62s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)): 0.25s\n",
      "I0128 19:33:45.698931 140105121920832 test_util.py:2189] time(__main__.ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)): 0.25s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model_from_keypoints\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model_from_keypoints): 0.19s\n",
      "I0128 19:33:45.885250 140105121920832 test_util.py:2189] time(__main__.ModelBuilderTF2Test.test_create_center_net_model_from_keypoints): 0.19s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_center_net_model_from_keypoints\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model_mobilenet\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model_mobilenet): 2.8s\n",
      "I0128 19:33:48.681677 140105121920832 test_util.py:2189] time(__main__.ModelBuilderTF2Test.test_create_center_net_model_mobilenet): 2.8s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_center_net_model_mobilenet\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_experimental_model\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_experimental_model): 0.0s\n",
      "I0128 19:33:48.682307 140105121920832 test_util.py:2189] time(__main__.ModelBuilderTF2Test.test_create_experimental_model): 0.0s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_experimental_model\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)): 0.03s\n",
      "I0128 19:33:48.708544 140105121920832 test_util.py:2189] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)): 0.03s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)): 0.01s\n",
      "I0128 19:33:48.718966 140105121920832 test_util.py:2189] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)): 0.01s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner): 0.01s\n",
      "I0128 19:33:48.731030 140105121920832 test_util.py:2189] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner): 0.01s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul): 0.08s\n",
      "I0128 19:33:48.810106 140105121920832 test_util.py:2189] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul): 0.08s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul): 0.07s\n",
      "I0128 19:33:48.879128 140105121920832 test_util.py:2189] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul): 0.07s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul): 0.07s\n",
      "I0128 19:33:48.952783 140105121920832 test_util.py:2189] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul): 0.07s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul): 0.07s\n",
      "I0128 19:33:49.026635 140105121920832 test_util.py:2189] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul): 0.07s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_rfcn_model_from_config\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_rfcn_model_from_config): 0.07s\n",
      "I0128 19:33:49.099411 140105121920832 test_util.py:2189] time(__main__.ModelBuilderTF2Test.test_create_rfcn_model_from_config): 0.07s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_rfcn_model_from_config\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config): 0.02s\n",
      "I0128 19:33:49.123716 140105121920832 test_util.py:2189] time(__main__.ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config): 0.02s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_ssd_models_from_config\n",
      "I0128 19:33:49.326119 140105121920832 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b0\n",
      "I0128 19:33:49.326288 140105121920832 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 64\n",
      "I0128 19:33:49.326331 140105121920832 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 3\n",
      "I0128 19:33:49.328650 140105121920832 efficientnet_model.py:147] round_filter input=32 output=32\n",
      "I0128 19:33:49.340144 140105121920832 efficientnet_model.py:147] round_filter input=32 output=32\n",
      "I0128 19:33:49.340237 140105121920832 efficientnet_model.py:147] round_filter input=16 output=16\n",
      "I0128 19:33:49.375555 140105121920832 efficientnet_model.py:147] round_filter input=16 output=16\n",
      "I0128 19:33:49.375637 140105121920832 efficientnet_model.py:147] round_filter input=24 output=24\n",
      "I0128 19:33:49.466894 140105121920832 efficientnet_model.py:147] round_filter input=24 output=24\n",
      "I0128 19:33:49.466986 140105121920832 efficientnet_model.py:147] round_filter input=40 output=40\n",
      "I0128 19:33:49.557546 140105121920832 efficientnet_model.py:147] round_filter input=40 output=40\n",
      "I0128 19:33:49.557634 140105121920832 efficientnet_model.py:147] round_filter input=80 output=80\n",
      "I0128 19:33:49.700785 140105121920832 efficientnet_model.py:147] round_filter input=80 output=80\n",
      "I0128 19:33:49.700893 140105121920832 efficientnet_model.py:147] round_filter input=112 output=112\n",
      "I0128 19:33:49.846320 140105121920832 efficientnet_model.py:147] round_filter input=112 output=112\n",
      "I0128 19:33:49.846425 140105121920832 efficientnet_model.py:147] round_filter input=192 output=192\n",
      "I0128 19:33:50.040185 140105121920832 efficientnet_model.py:147] round_filter input=192 output=192\n",
      "I0128 19:33:50.040280 140105121920832 efficientnet_model.py:147] round_filter input=320 output=320\n",
      "I0128 19:33:50.089219 140105121920832 efficientnet_model.py:147] round_filter input=1280 output=1280\n",
      "I0128 19:33:50.113773 140105121920832 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.0, resolution=224, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
      "I0128 19:33:50.153172 140105121920832 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b1\n",
      "I0128 19:33:50.153269 140105121920832 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 88\n",
      "I0128 19:33:50.153313 140105121920832 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 4\n",
      "I0128 19:33:50.154449 140105121920832 efficientnet_model.py:147] round_filter input=32 output=32\n",
      "I0128 19:33:50.163850 140105121920832 efficientnet_model.py:147] round_filter input=32 output=32\n",
      "I0128 19:33:50.163922 140105121920832 efficientnet_model.py:147] round_filter input=16 output=16\n",
      "I0128 19:33:50.235111 140105121920832 efficientnet_model.py:147] round_filter input=16 output=16\n",
      "I0128 19:33:50.235201 140105121920832 efficientnet_model.py:147] round_filter input=24 output=24\n",
      "I0128 19:33:50.372401 140105121920832 efficientnet_model.py:147] round_filter input=24 output=24\n",
      "I0128 19:33:50.372492 140105121920832 efficientnet_model.py:147] round_filter input=40 output=40\n",
      "I0128 19:33:50.510729 140105121920832 efficientnet_model.py:147] round_filter input=40 output=40\n",
      "I0128 19:33:50.510818 140105121920832 efficientnet_model.py:147] round_filter input=80 output=80\n",
      "I0128 19:33:50.698102 140105121920832 efficientnet_model.py:147] round_filter input=80 output=80\n",
      "I0128 19:33:50.698199 140105121920832 efficientnet_model.py:147] round_filter input=112 output=112\n",
      "I0128 19:33:50.904532 140105121920832 efficientnet_model.py:147] round_filter input=112 output=112\n",
      "I0128 19:33:50.904622 140105121920832 efficientnet_model.py:147] round_filter input=192 output=192\n",
      "I0128 19:33:51.157047 140105121920832 efficientnet_model.py:147] round_filter input=192 output=192\n",
      "I0128 19:33:51.157139 140105121920832 efficientnet_model.py:147] round_filter input=320 output=320\n",
      "I0128 19:33:51.260842 140105121920832 efficientnet_model.py:147] round_filter input=1280 output=1280\n",
      "I0128 19:33:51.282918 140105121920832 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.1, resolution=240, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
      "I0128 19:33:51.388157 140105121920832 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b2\n",
      "I0128 19:33:51.388245 140105121920832 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 112\n",
      "I0128 19:33:51.388319 140105121920832 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 5\n",
      "I0128 19:33:51.389531 140105121920832 efficientnet_model.py:147] round_filter input=32 output=32\n",
      "I0128 19:33:51.398536 140105121920832 efficientnet_model.py:147] round_filter input=32 output=32\n",
      "I0128 19:33:51.398595 140105121920832 efficientnet_model.py:147] round_filter input=16 output=16\n",
      "I0128 19:33:51.470684 140105121920832 efficientnet_model.py:147] round_filter input=16 output=16\n",
      "I0128 19:33:51.470771 140105121920832 efficientnet_model.py:147] round_filter input=24 output=24\n",
      "I0128 19:33:51.609583 140105121920832 efficientnet_model.py:147] round_filter input=24 output=24\n",
      "I0128 19:33:51.609673 140105121920832 efficientnet_model.py:147] round_filter input=40 output=48\n",
      "I0128 19:33:51.751332 140105121920832 efficientnet_model.py:147] round_filter input=40 output=48\n",
      "I0128 19:33:51.751424 140105121920832 efficientnet_model.py:147] round_filter input=80 output=88\n",
      "I0128 19:33:51.942878 140105121920832 efficientnet_model.py:147] round_filter input=80 output=88\n",
      "I0128 19:33:51.942972 140105121920832 efficientnet_model.py:147] round_filter input=112 output=120\n",
      "I0128 19:33:52.137608 140105121920832 efficientnet_model.py:147] round_filter input=112 output=120\n",
      "I0128 19:33:52.137698 140105121920832 efficientnet_model.py:147] round_filter input=192 output=208\n",
      "I0128 19:33:52.385627 140105121920832 efficientnet_model.py:147] round_filter input=192 output=208\n",
      "I0128 19:33:52.385718 140105121920832 efficientnet_model.py:147] round_filter input=320 output=352\n",
      "I0128 19:33:52.514379 140105121920832 efficientnet_model.py:147] round_filter input=1280 output=1408\n",
      "I0128 19:33:52.537152 140105121920832 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=1.1, depth_coefficient=1.2, resolution=260, dropout_rate=0.3, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
      "I0128 19:33:52.581769 140105121920832 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b3\n",
      "I0128 19:33:52.581866 140105121920832 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 160\n",
      "I0128 19:33:52.581912 140105121920832 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 6\n",
      "I0128 19:33:52.583106 140105121920832 efficientnet_model.py:147] round_filter input=32 output=40\n",
      "I0128 19:33:52.592879 140105121920832 efficientnet_model.py:147] round_filter input=32 output=40\n",
      "I0128 19:33:52.592966 140105121920832 efficientnet_model.py:147] round_filter input=16 output=24\n",
      "I0128 19:33:52.666576 140105121920832 efficientnet_model.py:147] round_filter input=16 output=24\n",
      "I0128 19:33:52.666668 140105121920832 efficientnet_model.py:147] round_filter input=24 output=32\n",
      "I0128 19:33:52.802280 140105121920832 efficientnet_model.py:147] round_filter input=24 output=32\n",
      "I0128 19:33:52.802369 140105121920832 efficientnet_model.py:147] round_filter input=40 output=48\n",
      "I0128 19:33:52.939547 140105121920832 efficientnet_model.py:147] round_filter input=40 output=48\n",
      "I0128 19:33:52.939635 140105121920832 efficientnet_model.py:147] round_filter input=80 output=96\n",
      "I0128 19:33:53.187337 140105121920832 efficientnet_model.py:147] round_filter input=80 output=96\n",
      "I0128 19:33:53.187431 140105121920832 efficientnet_model.py:147] round_filter input=112 output=136\n",
      "I0128 19:33:53.428501 140105121920832 efficientnet_model.py:147] round_filter input=112 output=136\n",
      "I0128 19:33:53.428595 140105121920832 efficientnet_model.py:147] round_filter input=192 output=232\n",
      "I0128 19:33:53.732455 140105121920832 efficientnet_model.py:147] round_filter input=192 output=232\n",
      "I0128 19:33:53.732548 140105121920832 efficientnet_model.py:147] round_filter input=320 output=384\n",
      "I0128 19:33:53.840377 140105121920832 efficientnet_model.py:147] round_filter input=1280 output=1536\n",
      "I0128 19:33:53.866050 140105121920832 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=1.2, depth_coefficient=1.4, resolution=300, dropout_rate=0.3, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
      "I0128 19:33:53.916634 140105121920832 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b4\n",
      "I0128 19:33:53.916727 140105121920832 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 224\n",
      "I0128 19:33:53.916772 140105121920832 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 7\n",
      "I0128 19:33:53.917991 140105121920832 efficientnet_model.py:147] round_filter input=32 output=48\n",
      "I0128 19:33:54.036414 140105121920832 efficientnet_model.py:147] round_filter input=32 output=48\n",
      "I0128 19:33:54.036503 140105121920832 efficientnet_model.py:147] round_filter input=16 output=24\n",
      "I0128 19:33:54.112387 140105121920832 efficientnet_model.py:147] round_filter input=16 output=24\n",
      "I0128 19:33:54.112490 140105121920832 efficientnet_model.py:147] round_filter input=24 output=32\n",
      "I0128 19:33:54.303168 140105121920832 efficientnet_model.py:147] round_filter input=24 output=32\n",
      "I0128 19:33:54.303259 140105121920832 efficientnet_model.py:147] round_filter input=40 output=56\n",
      "I0128 19:33:54.494777 140105121920832 efficientnet_model.py:147] round_filter input=40 output=56\n",
      "I0128 19:33:54.494879 140105121920832 efficientnet_model.py:147] round_filter input=80 output=112\n",
      "I0128 19:33:54.799539 140105121920832 efficientnet_model.py:147] round_filter input=80 output=112\n",
      "I0128 19:33:54.799632 140105121920832 efficientnet_model.py:147] round_filter input=112 output=160\n",
      "I0128 19:33:55.088392 140105121920832 efficientnet_model.py:147] round_filter input=112 output=160\n",
      "I0128 19:33:55.088515 140105121920832 efficientnet_model.py:147] round_filter input=192 output=272\n",
      "I0128 19:33:55.505725 140105121920832 efficientnet_model.py:147] round_filter input=192 output=272\n",
      "I0128 19:33:55.505822 140105121920832 efficientnet_model.py:147] round_filter input=320 output=448\n",
      "I0128 19:33:55.618765 140105121920832 efficientnet_model.py:147] round_filter input=1280 output=1792\n",
      "I0128 19:33:55.643025 140105121920832 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=1.4, depth_coefficient=1.8, resolution=380, dropout_rate=0.4, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
      "I0128 19:33:55.701316 140105121920832 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b5\n",
      "I0128 19:33:55.701407 140105121920832 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 288\n",
      "I0128 19:33:55.701453 140105121920832 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 7\n",
      "I0128 19:33:55.702625 140105121920832 efficientnet_model.py:147] round_filter input=32 output=48\n",
      "I0128 19:33:55.712412 140105121920832 efficientnet_model.py:147] round_filter input=32 output=48\n",
      "I0128 19:33:55.712478 140105121920832 efficientnet_model.py:147] round_filter input=16 output=24\n",
      "I0128 19:33:55.824193 140105121920832 efficientnet_model.py:147] round_filter input=16 output=24\n",
      "I0128 19:33:55.824286 140105121920832 efficientnet_model.py:147] round_filter input=24 output=40\n",
      "I0128 19:33:56.062349 140105121920832 efficientnet_model.py:147] round_filter input=24 output=40\n",
      "I0128 19:33:56.062439 140105121920832 efficientnet_model.py:147] round_filter input=40 output=64\n",
      "I0128 19:33:56.309484 140105121920832 efficientnet_model.py:147] round_filter input=40 output=64\n",
      "I0128 19:33:56.309573 140105121920832 efficientnet_model.py:147] round_filter input=80 output=128\n",
      "I0128 19:33:56.643333 140105121920832 efficientnet_model.py:147] round_filter input=80 output=128\n",
      "I0128 19:33:56.643423 140105121920832 efficientnet_model.py:147] round_filter input=112 output=176\n",
      "I0128 19:33:57.085824 140105121920832 efficientnet_model.py:147] round_filter input=112 output=176\n",
      "I0128 19:33:57.085916 140105121920832 efficientnet_model.py:147] round_filter input=192 output=304\n",
      "I0128 19:33:57.567382 140105121920832 efficientnet_model.py:147] round_filter input=192 output=304\n",
      "I0128 19:33:57.567476 140105121920832 efficientnet_model.py:147] round_filter input=320 output=512\n",
      "I0128 19:33:57.751624 140105121920832 efficientnet_model.py:147] round_filter input=1280 output=2048\n",
      "I0128 19:33:57.778041 140105121920832 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=1.6, depth_coefficient=2.2, resolution=456, dropout_rate=0.4, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
      "I0128 19:33:57.843634 140105121920832 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b6\n",
      "I0128 19:33:57.843731 140105121920832 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 384\n",
      "I0128 19:33:57.843779 140105121920832 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 8\n",
      "I0128 19:33:57.844967 140105121920832 efficientnet_model.py:147] round_filter input=32 output=56\n",
      "I0128 19:33:57.854499 140105121920832 efficientnet_model.py:147] round_filter input=32 output=56\n",
      "I0128 19:33:57.854563 140105121920832 efficientnet_model.py:147] round_filter input=16 output=32\n",
      "I0128 19:33:57.965333 140105121920832 efficientnet_model.py:147] round_filter input=16 output=32\n",
      "I0128 19:33:57.965425 140105121920832 efficientnet_model.py:147] round_filter input=24 output=40\n",
      "I0128 19:33:58.267519 140105121920832 efficientnet_model.py:147] round_filter input=24 output=40\n",
      "I0128 19:33:58.267615 140105121920832 efficientnet_model.py:147] round_filter input=40 output=72\n",
      "I0128 19:33:58.556799 140105121920832 efficientnet_model.py:147] round_filter input=40 output=72\n",
      "I0128 19:33:58.556894 140105121920832 efficientnet_model.py:147] round_filter input=80 output=144\n",
      "I0128 19:33:58.958029 140105121920832 efficientnet_model.py:147] round_filter input=80 output=144\n",
      "I0128 19:33:58.958122 140105121920832 efficientnet_model.py:147] round_filter input=112 output=200\n",
      "I0128 19:33:59.378196 140105121920832 efficientnet_model.py:147] round_filter input=112 output=200\n",
      "I0128 19:33:59.378290 140105121920832 efficientnet_model.py:147] round_filter input=192 output=344\n",
      "I0128 19:34:00.094019 140105121920832 efficientnet_model.py:147] round_filter input=192 output=344\n",
      "I0128 19:34:00.094114 140105121920832 efficientnet_model.py:147] round_filter input=320 output=576\n",
      "I0128 19:34:00.288045 140105121920832 efficientnet_model.py:147] round_filter input=1280 output=2304\n",
      "I0128 19:34:00.315615 140105121920832 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=1.8, depth_coefficient=2.6, resolution=528, dropout_rate=0.5, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
      "I0128 19:34:00.387177 140105121920832 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b7\n",
      "I0128 19:34:00.387271 140105121920832 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 384\n",
      "I0128 19:34:00.387318 140105121920832 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 8\n",
      "I0128 19:34:00.388510 140105121920832 efficientnet_model.py:147] round_filter input=32 output=64\n",
      "I0128 19:34:00.397918 140105121920832 efficientnet_model.py:147] round_filter input=32 output=64\n",
      "I0128 19:34:00.397982 140105121920832 efficientnet_model.py:147] round_filter input=16 output=32\n",
      "I0128 19:34:00.549520 140105121920832 efficientnet_model.py:147] round_filter input=16 output=32\n",
      "I0128 19:34:00.549614 140105121920832 efficientnet_model.py:147] round_filter input=24 output=48\n",
      "I0128 19:34:00.879625 140105121920832 efficientnet_model.py:147] round_filter input=24 output=48\n",
      "I0128 19:34:00.879716 140105121920832 efficientnet_model.py:147] round_filter input=40 output=80\n",
      "I0128 19:34:01.212572 140105121920832 efficientnet_model.py:147] round_filter input=40 output=80\n",
      "I0128 19:34:01.212665 140105121920832 efficientnet_model.py:147] round_filter input=80 output=160\n",
      "I0128 19:34:01.704591 140105121920832 efficientnet_model.py:147] round_filter input=80 output=160\n",
      "I0128 19:34:01.704682 140105121920832 efficientnet_model.py:147] round_filter input=112 output=224\n",
      "I0128 19:34:02.211632 140105121920832 efficientnet_model.py:147] round_filter input=112 output=224\n",
      "I0128 19:34:02.211726 140105121920832 efficientnet_model.py:147] round_filter input=192 output=384\n",
      "I0128 19:34:02.944280 140105121920832 efficientnet_model.py:147] round_filter input=192 output=384\n",
      "I0128 19:34:02.944378 140105121920832 efficientnet_model.py:147] round_filter input=320 output=640\n",
      "I0128 19:34:03.215511 140105121920832 efficientnet_model.py:147] round_filter input=1280 output=2560\n",
      "I0128 19:34:03.244955 140105121920832 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=2.0, depth_coefficient=3.1, resolution=600, dropout_rate=0.5, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_ssd_models_from_config): 14.32s\n",
      "I0128 19:34:03.443714 140105121920832 test_util.py:2189] time(__main__.ModelBuilderTF2Test.test_create_ssd_models_from_config): 14.32s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_ssd_models_from_config\n",
      "[ RUN      ] ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update): 0.0s\n",
      "I0128 19:34:03.449585 140105121920832 test_util.py:2189] time(__main__.ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update): 0.0s\n",
      "[       OK ] ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update\n",
      "[ RUN      ] ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold): 0.0s\n",
      "I0128 19:34:03.450695 140105121920832 test_util.py:2189] time(__main__.ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold): 0.0s\n",
      "[       OK ] ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold\n",
      "[ RUN      ] ModelBuilderTF2Test.test_invalid_model_config_proto\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_model_config_proto): 0.0s\n",
      "I0128 19:34:03.450942 140105121920832 test_util.py:2189] time(__main__.ModelBuilderTF2Test.test_invalid_model_config_proto): 0.0s\n",
      "[       OK ] ModelBuilderTF2Test.test_invalid_model_config_proto\n",
      "[ RUN      ] ModelBuilderTF2Test.test_invalid_second_stage_batch_size\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_second_stage_batch_size): 0.0s\n",
      "I0128 19:34:03.451897 140105121920832 test_util.py:2189] time(__main__.ModelBuilderTF2Test.test_invalid_second_stage_batch_size): 0.0s\n",
      "[       OK ] ModelBuilderTF2Test.test_invalid_second_stage_batch_size\n",
      "[ RUN      ] ModelBuilderTF2Test.test_session\n",
      "[  SKIPPED ] ModelBuilderTF2Test.test_session\n",
      "[ RUN      ] ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor): 0.0s\n",
      "I0128 19:34:03.452786 140105121920832 test_util.py:2189] time(__main__.ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor): 0.0s\n",
      "[       OK ] ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor\n",
      "[ RUN      ] ModelBuilderTF2Test.test_unknown_meta_architecture\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_meta_architecture): 0.0s\n",
      "I0128 19:34:03.453005 140105121920832 test_util.py:2189] time(__main__.ModelBuilderTF2Test.test_unknown_meta_architecture): 0.0s\n",
      "[       OK ] ModelBuilderTF2Test.test_unknown_meta_architecture\n",
      "[ RUN      ] ModelBuilderTF2Test.test_unknown_ssd_feature_extractor\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_ssd_feature_extractor): 0.0s\n",
      "I0128 19:34:03.453634 140105121920832 test_util.py:2189] time(__main__.ModelBuilderTF2Test.test_unknown_ssd_feature_extractor): 0.0s\n",
      "[       OK ] ModelBuilderTF2Test.test_unknown_ssd_feature_extractor\n",
      "----------------------------------------------------------------------\n",
      "Ran 24 tests in 19.320s\n",
      "\n",
      "OK (skipped=1)\n"
     ]
    }
   ],
   "source": [
    "VERIFICATION_SCRIPT = os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection', 'builders', 'model_builder_tf2_test.py')\n",
    "# Verify Installation\n",
    "!python3 {VERIFICATION_SCRIPT}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import object_detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-01-28 19:34:07--  http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz\n",
      "Resolving download.tensorflow.org (download.tensorflow.org)... 142.250.187.144, 2a00:1450:4017:807::2010\n",
      "Connecting to download.tensorflow.org (download.tensorflow.org)|142.250.187.144|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 20515344 (20M) [application/x-tar]\n",
      "Saving to: âssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gzâ\n",
      "\n",
      "ssd_mobilenet_v2_fp 100%[===================>]  19,56M  1,97MB/s    in 14s     \n",
      "\n",
      "2022-01-28 19:34:22 (1,43 MB/s) - âssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gzâ saved [20515344/20515344]\n",
      "\n",
      "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/\n",
      "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/checkpoint/\n",
      "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/checkpoint/ckpt-0.data-00000-of-00001\n",
      "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/checkpoint/checkpoint\n",
      "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/checkpoint/ckpt-0.index\n",
      "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/pipeline.config\n",
      "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/saved_model/\n",
      "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/saved_model/saved_model.pb\n",
      "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/saved_model/variables/\n",
      "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/saved_model/variables/variables.data-00000-of-00001\n",
      "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/saved_model/variables/variables.index\n"
     ]
    }
   ],
   "source": [
    "if os.name =='posix':\n",
    "    !wget {PRETRAINED_MODEL_URL}\n",
    "    !mv {PRETRAINED_MODEL_NAME+'.tar.gz'} {paths['PRETRAINED_MODEL_PATH']}\n",
    "    !cd {paths['PRETRAINED_MODEL_PATH']} && tar -zxvf {PRETRAINED_MODEL_NAME+'.tar.gz'}\n",
    "if os.name == 'nt':\n",
    "    wget.download(PRETRAINED_MODEL_URL)\n",
    "    !move {PRETRAINED_MODEL_NAME+'.tar.gz'} {paths['PRETRAINED_MODEL_PATH']}\n",
    "    !cd {paths['PRETRAINED_MODEL_PATH']} && tar -zxvf {PRETRAINED_MODEL_NAME+'.tar.gz'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [{'name':'with_mask', 'id':1}, {'name':'without_mask', 'id':2}, {'name':'mask_weared_incorrect', 'id':3}]\n",
    "\n",
    "with open(files['LABELMAP'], 'w') as f:\n",
    "    for label in labels:\n",
    "        f.write('item { \\n')\n",
    "        f.write('\\tname:\\'{}\\'\\n'.format(label['name']))\n",
    "        f.write('\\tid:{}\\n'.format(label['id']))\n",
    "        f.write('}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTIONAL IF RUNNING ON COLAB\n",
    "ARCHIVE_FILES = os.path.join(paths['IMAGE_PATH'], 'archive.tar.gz')\n",
    "if os.path.exists(ARCHIVE_FILES):\n",
    "  !tar -zxvf {ARCHIVE_FILES}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if not os.path.exists(files['TF_RECORD_SCRIPT']):\n",
    "    !git clone https://github.com/nicknochnack/GenerateTFRecord {paths['SCRIPTS_PATH']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully created the TFRecord file: Tensorflow/workspace/annotations/train.record\n",
      "Successfully created the TFRecord file: Tensorflow/workspace/annotations/test.record\n"
     ]
    }
   ],
   "source": [
    "!python3 {files['TF_RECORD_SCRIPT']} -x {os.path.join(paths['IMAGE_PATH'], 'train')} -l {files['LABELMAP']} -o {os.path.join(paths['ANNOTATION_PATH'], 'train.record')} \n",
    "!python3 {files['TF_RECORD_SCRIPT']} -x {os.path.join(paths['IMAGE_PATH'], 'test')} -l {files['LABELMAP']} -o {os.path.join(paths['ANNOTATION_PATH'], 'test.record')} "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copy Model Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.name =='posix':\n",
    "    !cp {os.path.join(paths['PRETRAINED_MODEL_PATH'], PRETRAINED_MODEL_NAME, 'pipeline.config')} {os.path.join(paths['CHECKPOINT_PATH'])}\n",
    "if os.name == 'nt':\n",
    "    !copy {os.path.join(paths['PRETRAINED_MODEL_PATH'], PRETRAINED_MODEL_NAME, 'pipeline.config')} {os.path.join("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from object_detection.utils import config_util\n",
    "from object_detection.protos import pipeline_pb2\n",
    "from google.protobuf import text_format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = config_util.get_configs_from_pipeline_file(files['PIPELINE_CONFIG'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model': ssd {\n",
       "   num_classes: 90\n",
       "   image_resizer {\n",
       "     fixed_shape_resizer {\n",
       "       height: 320\n",
       "       width: 320\n",
       "     }\n",
       "   }\n",
       "   feature_extractor {\n",
       "     type: \"ssd_mobilenet_v2_fpn_keras\"\n",
       "     depth_multiplier: 1.0\n",
       "     min_depth: 16\n",
       "     conv_hyperparams {\n",
       "       regularizer {\n",
       "         l2_regularizer {\n",
       "           weight: 3.9999998989515007e-05\n",
       "         }\n",
       "       }\n",
       "       initializer {\n",
       "         random_normal_initializer {\n",
       "           mean: 0.0\n",
       "           stddev: 0.009999999776482582\n",
       "         }\n",
       "       }\n",
       "       activation: RELU_6\n",
       "       batch_norm {\n",
       "         decay: 0.996999979019165\n",
       "         scale: true\n",
       "         epsilon: 0.0010000000474974513\n",
       "       }\n",
       "     }\n",
       "     use_depthwise: true\n",
       "     override_base_feature_extractor_hyperparams: true\n",
       "     fpn {\n",
       "       min_level: 3\n",
       "       max_level: 7\n",
       "       additional_layer_depth: 128\n",
       "     }\n",
       "   }\n",
       "   box_coder {\n",
       "     faster_rcnn_box_coder {\n",
       "       y_scale: 10.0\n",
       "       x_scale: 10.0\n",
       "       height_scale: 5.0\n",
       "       width_scale: 5.0\n",
       "     }\n",
       "   }\n",
       "   matcher {\n",
       "     argmax_matcher {\n",
       "       matched_threshold: 0.5\n",
       "       unmatched_threshold: 0.5\n",
       "       ignore_thresholds: false\n",
       "       negatives_lower_than_unmatched: true\n",
       "       force_match_for_each_row: true\n",
       "       use_matmul_gather: true\n",
       "     }\n",
       "   }\n",
       "   similarity_calculator {\n",
       "     iou_similarity {\n",
       "     }\n",
       "   }\n",
       "   box_predictor {\n",
       "     weight_shared_convolutional_box_predictor {\n",
       "       conv_hyperparams {\n",
       "         regularizer {\n",
       "           l2_regularizer {\n",
       "             weight: 3.9999998989515007e-05\n",
       "           }\n",
       "         }\n",
       "         initializer {\n",
       "           random_normal_initializer {\n",
       "             mean: 0.0\n",
       "             stddev: 0.009999999776482582\n",
       "           }\n",
       "         }\n",
       "         activation: RELU_6\n",
       "         batch_norm {\n",
       "           decay: 0.996999979019165\n",
       "           scale: true\n",
       "           epsilon: 0.0010000000474974513\n",
       "         }\n",
       "       }\n",
       "       depth: 128\n",
       "       num_layers_before_predictor: 4\n",
       "       kernel_size: 3\n",
       "       class_prediction_bias_init: -4.599999904632568\n",
       "       share_prediction_tower: true\n",
       "       use_depthwise: true\n",
       "     }\n",
       "   }\n",
       "   anchor_generator {\n",
       "     multiscale_anchor_generator {\n",
       "       min_level: 3\n",
       "       max_level: 7\n",
       "       anchor_scale: 4.0\n",
       "       aspect_ratios: 1.0\n",
       "       aspect_ratios: 2.0\n",
       "       aspect_ratios: 0.5\n",
       "       scales_per_octave: 2\n",
       "     }\n",
       "   }\n",
       "   post_processing {\n",
       "     batch_non_max_suppression {\n",
       "       score_threshold: 9.99999993922529e-09\n",
       "       iou_threshold: 0.6000000238418579\n",
       "       max_detections_per_class: 100\n",
       "       max_total_detections: 100\n",
       "       use_static_shapes: false\n",
       "     }\n",
       "     score_converter: SIGMOID\n",
       "   }\n",
       "   normalize_loss_by_num_matches: true\n",
       "   loss {\n",
       "     localization_loss {\n",
       "       weighted_smooth_l1 {\n",
       "       }\n",
       "     }\n",
       "     classification_loss {\n",
       "       weighted_sigmoid_focal {\n",
       "         gamma: 2.0\n",
       "         alpha: 0.25\n",
       "       }\n",
       "     }\n",
       "     classification_weight: 1.0\n",
       "     localization_weight: 1.0\n",
       "   }\n",
       "   encode_background_as_zeros: true\n",
       "   normalize_loc_loss_by_codesize: true\n",
       "   inplace_batchnorm_update: true\n",
       "   freeze_batchnorm: false\n",
       " },\n",
       " 'train_config': batch_size: 128\n",
       " data_augmentation_options {\n",
       "   random_horizontal_flip {\n",
       "   }\n",
       " }\n",
       " data_augmentation_options {\n",
       "   random_crop_image {\n",
       "     min_object_covered: 0.0\n",
       "     min_aspect_ratio: 0.75\n",
       "     max_aspect_ratio: 3.0\n",
       "     min_area: 0.75\n",
       "     max_area: 1.0\n",
       "     overlap_thresh: 0.0\n",
       "   }\n",
       " }\n",
       " sync_replicas: true\n",
       " optimizer {\n",
       "   momentum_optimizer {\n",
       "     learning_rate {\n",
       "       cosine_decay_learning_rate {\n",
       "         learning_rate_base: 0.07999999821186066\n",
       "         total_steps: 50000\n",
       "         warmup_learning_rate: 0.026666000485420227\n",
       "         warmup_steps: 1000\n",
       "       }\n",
       "     }\n",
       "     momentum_optimizer_value: 0.8999999761581421\n",
       "   }\n",
       "   use_moving_average: false\n",
       " }\n",
       " fine_tune_checkpoint: \"PATH_TO_BE_CONFIGURED\"\n",
       " num_steps: 50000\n",
       " startup_delay_steps: 0.0\n",
       " replicas_to_aggregate: 8\n",
       " max_number_of_boxes: 100\n",
       " unpad_groundtruth_tensors: false\n",
       " fine_tune_checkpoint_type: \"classification\"\n",
       " fine_tune_checkpoint_version: V2,\n",
       " 'train_input_config': label_map_path: \"PATH_TO_BE_CONFIGURED\"\n",
       " tf_record_input_reader {\n",
       "   input_path: \"PATH_TO_BE_CONFIGURED\"\n",
       " },\n",
       " 'eval_config': metrics_set: \"coco_detection_metrics\"\n",
       " use_moving_averages: false,\n",
       " 'eval_input_configs': [label_map_path: \"PATH_TO_BE_CONFIGURED\"\n",
       " shuffle: false\n",
       " num_epochs: 1\n",
       " tf_record_input_reader {\n",
       "   input_path: \"PATH_TO_BE_CONFIGURED\"\n",
       " }\n",
       " ],\n",
       " 'eval_input_config': label_map_path: \"PATH_TO_BE_CONFIGURED\"\n",
       " shuffle: false\n",
       " num_epochs: 1\n",
       " tf_record_input_reader {\n",
       "   input_path: \"PATH_TO_BE_CONFIGURED\"\n",
       " }}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_config = pipeline_pb2.TrainEvalPipelineConfig()\n",
    "with tf.io.gfile.GFile(files['PIPELINE_CONFIG'], \"r\") as f:                                                                                                                                                                                                                     \n",
    "    proto_str = f.read()                                                                                                                                                                                                                                          \n",
    "    text_format.Merge(proto_str, pipeline_config)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_config.model.ssd.num_classes = len(labels)\n",
    "pipeline_config.train_config.batch_size = 4\n",
    "pipeline_config.train_config.fine_tune_checkpoint = os.path.join(paths['PRETRAINED_MODEL_PATH'], PRETRAINED_MODEL_NAME, 'checkpoint', 'ckpt-0')\n",
    "pipeline_config.train_config.fine_tune_checkpoint_type = \"detection\"\n",
    "pipeline_config.train_input_reader.label_map_path= files['LABELMAP']\n",
    "pipeline_config.train_input_reader.tf_record_input_reader.input_path[:] = [os.path.join(paths['ANNOTATION_PATH'], 'train.record')]\n",
    "pipeline_config.eval_input_reader[0].label_map_path = files['LABELMAP']\n",
    "pipeline_config.eval_input_reader[0].tf_record_input_reader.input_path[:] = [os.path.join(paths['ANNOTATION_PATH'], 'test.record')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_text = text_format.MessageToString(pipeline_config)                                                                                                                                                                                                        \n",
    "with tf.io.gfile.GFile(files['PIPELINE_CONFIG'], \"wb\") as f:                                                                                                                                                                                                                     \n",
    "    f.write(config_text)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINING_SCRIPT = os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection', 'model_main_tf2.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "command = \"python3 {} --model_dir={} --pipeline_config_path={} --num_train_steps=2000\".format(TRAINING_SCRIPT, paths['CHECKPOINT_PATH'],files['PIPELINE_CONFIG'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python3 Tensorflow/models/research/object_detection/model_main_tf2.py --model_dir=Tensorflow/workspace/models/my_ssd_mobnet --pipeline_config_path=Tensorflow/workspace/models/my_ssd_mobnet/pipeline.config --num_train_steps=2000\n"
     ]
    }
   ],
   "source": [
    "print(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-01-28 19:34:36.362515: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-01-28 19:34:36.362545: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2022-01-28 19:34:39.164056: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-28 19:34:39.164520: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/elif/.local/lib/python3.6/site-packages/cv2/../../lib64:\n",
      "2022-01-28 19:34:39.164598: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/elif/.local/lib/python3.6/site-packages/cv2/../../lib64:\n",
      "2022-01-28 19:34:39.164699: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/elif/.local/lib/python3.6/site-packages/cv2/../../lib64:\n",
      "2022-01-28 19:34:39.164783: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/elif/.local/lib/python3.6/site-packages/cv2/../../lib64:\n",
      "2022-01-28 19:34:39.164865: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/elif/.local/lib/python3.6/site-packages/cv2/../../lib64:\n",
      "2022-01-28 19:34:39.164949: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/elif/.local/lib/python3.6/site-packages/cv2/../../lib64:\n",
      "2022-01-28 19:34:39.165031: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/elif/.local/lib/python3.6/site-packages/cv2/../../lib64:\n",
      "2022-01-28 19:34:39.165098: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/elif/.local/lib/python3.6/site-packages/cv2/../../lib64:\n",
      "2022-01-28 19:34:39.165109: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1835] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2022-01-28 19:34:39.165594: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "WARNING:tensorflow:There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.\n",
      "W0128 19:34:39.166620 139914926520128 cross_device_ops.py:1387] There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n",
      "I0128 19:34:39.168873 139914926520128 mirrored_strategy.py:369] Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n",
      "INFO:tensorflow:Maybe overwriting train_steps: 2000\n",
      "I0128 19:34:39.172155 139914926520128 config_util.py:552] Maybe overwriting train_steps: 2000\n",
      "INFO:tensorflow:Maybe overwriting use_bfloat16: False\n",
      "I0128 19:34:39.172244 139914926520128 config_util.py:552] Maybe overwriting use_bfloat16: False\n",
      "WARNING:tensorflow:From /home/elif/.local/lib/python3.6/site-packages/object_detection/model_lib_v2.py:564: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "rename to distribute_datasets_from_function\n",
      "W0128 19:34:39.240077 139914926520128 deprecation.py:345] From /home/elif/.local/lib/python3.6/site-packages/object_detection/model_lib_v2.py:564: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "rename to distribute_datasets_from_function\n",
      "INFO:tensorflow:Reading unweighted datasets: ['Tensorflow/workspace/annotations/train.record']\n",
      "I0128 19:34:39.277021 139914926520128 dataset_builder.py:163] Reading unweighted datasets: ['Tensorflow/workspace/annotations/train.record']\n",
      "INFO:tensorflow:Reading record datasets for input file: ['Tensorflow/workspace/annotations/train.record']\n",
      "I0128 19:34:39.277184 139914926520128 dataset_builder.py:80] Reading record datasets for input file: ['Tensorflow/workspace/annotations/train.record']\n",
      "INFO:tensorflow:Number of filenames to read: 1\n",
      "I0128 19:34:39.277250 139914926520128 dataset_builder.py:81] Number of filenames to read: 1\n",
      "WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\n",
      "W0128 19:34:39.277306 139914926520128 dataset_builder.py:88] num_readers has been reduced to 1 to match input file shards.\n",
      "WARNING:tensorflow:From /home/elif/.local/lib/python3.6/site-packages/object_detection/builders/dataset_builder.py:105: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_deterministic`.\n",
      "W0128 19:34:39.314286 139914926520128 deprecation.py:345] From /home/elif/.local/lib/python3.6/site-packages/object_detection/builders/dataset_builder.py:105: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_deterministic`.\n",
      "WARNING:tensorflow:From /home/elif/.local/lib/python3.6/site-packages/object_detection/builders/dataset_builder.py:237: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.map()\n",
      "W0128 19:34:39.403492 139914926520128 deprecation.py:345] From /home/elif/.local/lib/python3.6/site-packages/object_detection/builders/dataset_builder.py:237: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.map()\n",
      "WARNING:tensorflow:From /home/elif/.local/lib/python3.6/site-packages/tensorflow/python/util/dispatch.py:206: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
      "W0128 19:34:45.764704 139914926520128 deprecation.py:345] From /home/elif/.local/lib/python3.6/site-packages/tensorflow/python/util/dispatch.py:206: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
      "WARNING:tensorflow:From /home/elif/.local/lib/python3.6/site-packages/tensorflow/python/util/dispatch.py:206: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n",
      "W0128 19:34:47.991410 139914926520128 deprecation.py:345] From /home/elif/.local/lib/python3.6/site-packages/tensorflow/python/util/dispatch.py:206: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n",
      "WARNING:tensorflow:From /home/elif/.local/lib/python3.6/site-packages/tensorflow/python/autograph/impl/api.py:464: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "W0128 19:34:49.184076 139914926520128 deprecation.py:345] From /home/elif/.local/lib/python3.6/site-packages/tensorflow/python/autograph/impl/api.py:464: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "2022-01-28 19:34:52.722527: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2022-01-28 19:34:53.250878: W tensorflow/core/framework/dataset.cc:679] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n",
      "/home/elif/.local/lib/python3.6/site-packages/keras/backend.py:401: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
      "  warnings.warn('`tf.keras.backend.set_learning_phase` is deprecated and '\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "W0128 19:35:09.310282 139914926520128 util.py:204] Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "W0128 19:35:09.310403 139914926520128 util.py:204] Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.momentum\n",
      "W0128 19:35:09.310457 139914926520128 util.py:204] Unresolved object in checkpoint: (root).optimizer.momentum\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "W0128 19:35:09.310554 139914926520128 util.py:212] A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n"
     ]
    }
   ],
   "source": [
    "!{command}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "command = \"python3 {} --model_dir={} --pipeline_config_path={} --checkpoint_dir={}\".format(TRAINING_SCRIPT, paths['CHECKPOINT_PATH'],files['PIPELINE_CONFIG'], paths['CHECKPOINT_PATH'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python3 Tensorflow/models/research/object_detection/model_main_tf2.py --model_dir=Tensorflow/workspace/models/my_ssd_mobnet --pipeline_config_path=Tensorflow/workspace/models/my_ssd_mobnet/pipeline.config --checkpoint_dir=Tensorflow/workspace/models/my_ssd_mobnet\n"
     ]
    }
   ],
   "source": [
    "print(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-01-28 19:35:10.511811: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-01-28 19:35:10.511847: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2022-01-28 19:35:12.396301: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-28 19:35:12.397289: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/elif/.local/lib/python3.6/site-packages/cv2/../../lib64:\n",
      "2022-01-28 19:35:12.397440: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/elif/.local/lib/python3.6/site-packages/cv2/../../lib64:\n",
      "2022-01-28 19:35:12.397668: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/elif/.local/lib/python3.6/site-packages/cv2/../../lib64:\n",
      "2022-01-28 19:35:12.397775: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/elif/.local/lib/python3.6/site-packages/cv2/../../lib64:\n",
      "2022-01-28 19:35:12.397935: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/elif/.local/lib/python3.6/site-packages/cv2/../../lib64:\n",
      "2022-01-28 19:35:12.398057: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/elif/.local/lib/python3.6/site-packages/cv2/../../lib64:\n",
      "2022-01-28 19:35:12.398162: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/elif/.local/lib/python3.6/site-packages/cv2/../../lib64:\n",
      "2022-01-28 19:35:12.398343: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/elif/.local/lib/python3.6/site-packages/cv2/../../lib64:\n",
      "2022-01-28 19:35:12.398379: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1835] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "WARNING:tensorflow:Forced number of epochs for all eval validations to be 1.\n",
      "W0128 19:35:12.402233 139739003512640 model_lib_v2.py:1090] Forced number of epochs for all eval validations to be 1.\n",
      "INFO:tensorflow:Maybe overwriting sample_1_of_n_eval_examples: None\n",
      "I0128 19:35:12.402406 139739003512640 config_util.py:552] Maybe overwriting sample_1_of_n_eval_examples: None\n",
      "INFO:tensorflow:Maybe overwriting use_bfloat16: False\n",
      "I0128 19:35:12.402500 139739003512640 config_util.py:552] Maybe overwriting use_bfloat16: False\n",
      "INFO:tensorflow:Maybe overwriting eval_num_epochs: 1\n",
      "I0128 19:35:12.402595 139739003512640 config_util.py:552] Maybe overwriting eval_num_epochs: 1\n",
      "WARNING:tensorflow:Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\n",
      "W0128 19:35:12.402699 139739003512640 model_lib_v2.py:1111] Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\n",
      "2022-01-28 19:35:12.405708: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "INFO:tensorflow:Reading unweighted datasets: ['Tensorflow/workspace/annotations/test.record']\n",
      "I0128 19:35:12.452254 139739003512640 dataset_builder.py:163] Reading unweighted datasets: ['Tensorflow/workspace/annotations/test.record']\n",
      "INFO:tensorflow:Reading record datasets for input file: ['Tensorflow/workspace/annotations/test.record']\n",
      "I0128 19:35:12.452408 139739003512640 dataset_builder.py:80] Reading record datasets for input file: ['Tensorflow/workspace/annotations/test.record']\n",
      "INFO:tensorflow:Number of filenames to read: 1\n",
      "I0128 19:35:12.452489 139739003512640 dataset_builder.py:81] Number of filenames to read: 1\n",
      "WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\n",
      "W0128 19:35:12.452565 139739003512640 dataset_builder.py:88] num_readers has been reduced to 1 to match input file shards.\n",
      "WARNING:tensorflow:From /home/elif/.local/lib/python3.6/site-packages/object_detection/builders/dataset_builder.py:105: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_deterministic`.\n",
      "W0128 19:35:12.453851 139739003512640 deprecation.py:345] From /home/elif/.local/lib/python3.6/site-packages/object_detection/builders/dataset_builder.py:105: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_deterministic`.\n",
      "WARNING:tensorflow:From /home/elif/.local/lib/python3.6/site-packages/object_detection/builders/dataset_builder.py:237: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.map()\n",
      "W0128 19:35:12.470312 139739003512640 deprecation.py:345] From /home/elif/.local/lib/python3.6/site-packages/object_detection/builders/dataset_builder.py:237: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.map()\n",
      "WARNING:tensorflow:From /home/elif/.local/lib/python3.6/site-packages/tensorflow/python/util/dispatch.py:206: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
      "W0128 19:35:15.544130 139739003512640 deprecation.py:345] From /home/elif/.local/lib/python3.6/site-packages/tensorflow/python/util/dispatch.py:206: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
      "WARNING:tensorflow:From /home/elif/.local/lib/python3.6/site-packages/tensorflow/python/autograph/impl/api.py:464: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "W0128 19:35:16.331631 139739003512640 deprecation.py:345] From /home/elif/.local/lib/python3.6/site-packages/tensorflow/python/autograph/impl/api.py:464: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "INFO:tensorflow:Waiting for new checkpoint at Tensorflow/workspace/models/my_ssd_mobnet\n",
      "I0128 19:35:18.122037 139739003512640 checkpoint_utils.py:140] Waiting for new checkpoint at Tensorflow/workspace/models/my_ssd_mobnet\n",
      "INFO:tensorflow:Found new checkpoint at Tensorflow/workspace/models/my_ssd_mobnet/ckpt-3\n",
      "I0128 19:35:18.122657 139739003512640 checkpoint_utils.py:149] Found new checkpoint at Tensorflow/workspace/models/my_ssd_mobnet/ckpt-3\n",
      "/home/elif/.local/lib/python3.6/site-packages/keras/backend.py:401: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
      "  warnings.warn('`tf.keras.backend.set_learning_phase` is deprecated and '\n",
      "2022-01-28 19:35:18.254157: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "WARNING:tensorflow:From /home/elif/.local/lib/python3.6/site-packages/object_detection/eval_util.py:929: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "W0128 19:35:33.553836 139739003512640 deprecation.py:345] From /home/elif/.local/lib/python3.6/site-packages/object_detection/eval_util.py:929: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "INFO:tensorflow:Finished eval step 0\n",
      "I0128 19:35:33.558465 139739003512640 model_lib_v2.py:966] Finished eval step 0\n",
      "WARNING:tensorflow:From /home/elif/.local/lib/python3.6/site-packages/tensorflow/python/autograph/impl/api.py:464: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "tf.py_func is deprecated in TF V2. Instead, there are two\n",
      "    options available in V2.\n",
      "    - tf.py_function takes a python function which manipulates tf eager\n",
      "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
      "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
      "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
      "    being differentiable using a gradient tape.\n",
      "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
      "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
      "    stateful argument making all functions stateful.\n",
      "    \n",
      "W0128 19:35:33.845288 139739003512640 deprecation.py:345] From /home/elif/.local/lib/python3.6/site-packages/tensorflow/python/autograph/impl/api.py:464: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "tf.py_func is deprecated in TF V2. Instead, there are two\n",
      "    options available in V2.\n",
      "    - tf.py_function takes a python function which manipulates tf eager\n",
      "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
      "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
      "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
      "    being differentiable using a gradient tape.\n",
      "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
      "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
      "    stateful argument making all functions stateful.\n",
      "    \n",
      "INFO:tensorflow:Performing evaluation on 30 images.\n",
      "I0128 19:35:36.178076 139739003512640 coco_evaluation.py:293] Performing evaluation on 30 images.\n",
      "creating index...\n",
      "index created!\n",
      "INFO:tensorflow:Loading and preparing annotation results...\n",
      "I0128 19:35:36.179209 139739003512640 coco_tools.py:116] Loading and preparing annotation results...\n",
      "INFO:tensorflow:DONE (t=0.00s)\n",
      "I0128 19:35:36.180642 139739003512640 coco_tools.py:138] DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.13s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.10s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
      "INFO:tensorflow:Eval metrics at step 2000\n",
      "I0128 19:35:36.419019 139739003512640 model_lib_v2.py:1015] Eval metrics at step 2000\n",
      "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP: 0.000000\n",
      "I0128 19:35:36.425186 139739003512640 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP: 0.000000\n",
      "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP@.50IOU: 0.000000\n",
      "I0128 19:35:36.426339 139739003512640 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP@.50IOU: 0.000000\n",
      "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP@.75IOU: 0.000000\n",
      "I0128 19:35:36.427188 139739003512640 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP@.75IOU: 0.000000\n",
      "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP (small): 0.000000\n",
      "I0128 19:35:36.428022 139739003512640 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP (small): 0.000000\n",
      "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP (medium): -1.000000\n",
      "I0128 19:35:36.428965 139739003512640 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP (medium): -1.000000\n",
      "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP (large): -1.000000\n",
      "I0128 19:35:36.429824 139739003512640 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP (large): -1.000000\n",
      "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@1: 0.000000\n",
      "I0128 19:35:36.430675 139739003512640 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@1: 0.000000\n",
      "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@10: 0.000000\n",
      "I0128 19:35:36.431440 139739003512640 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@10: 0.000000\n",
      "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100: 0.000000\n",
      "I0128 19:35:36.432120 139739003512640 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@100: 0.000000\n",
      "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100 (small): 0.000000\n",
      "I0128 19:35:36.432798 139739003512640 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@100 (small): 0.000000\n",
      "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100 (medium): -1.000000\n",
      "I0128 19:35:36.433496 139739003512640 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@100 (medium): -1.000000\n",
      "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100 (large): -1.000000\n",
      "I0128 19:35:36.434213 139739003512640 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@100 (large): -1.000000\n",
      "INFO:tensorflow:\t+ Loss/localization_loss: 3.009518\n",
      "I0128 19:35:36.434808 139739003512640 model_lib_v2.py:1018] \t+ Loss/localization_loss: 3.009518\n",
      "INFO:tensorflow:\t+ Loss/classification_loss: 4.770644\n",
      "I0128 19:35:36.435426 139739003512640 model_lib_v2.py:1018] \t+ Loss/classification_loss: 4.770644\n",
      "INFO:tensorflow:\t+ Loss/regularization_loss: 0.149370\n",
      "I0128 19:35:36.436039 139739003512640 model_lib_v2.py:1018] \t+ Loss/regularization_loss: 0.149370\n",
      "INFO:tensorflow:\t+ Loss/total_loss: 7.929532\n",
      "I0128 19:35:36.436571 139739003512640 model_lib_v2.py:1018] \t+ Loss/total_loss: 7.929532\n",
      "INFO:tensorflow:Waiting for new checkpoint at Tensorflow/workspace/models/my_ssd_mobnet\n",
      "I0128 19:40:18.221286 139739003512640 checkpoint_utils.py:140] Waiting for new checkpoint at Tensorflow/workspace/models/my_ssd_mobnet\n",
      "INFO:tensorflow:Timed-out waiting for a checkpoint.\n",
      "I0128 20:40:17.440208 139739003512640 checkpoint_utils.py:203] Timed-out waiting for a checkpoint.\n"
     ]
    }
   ],
   "source": [
    "!{command}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Train Model From Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from object_detection.utils import label_map_util\n",
    "from object_detection.utils import visualization_utils as viz_utils\n",
    "from object_detection.builders import model_builder\n",
    "from object_detection.utils import config_util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pipeline config and build a detection model\n",
    "configs = config_util.get_configs_from_pipeline_file(files['PIPELINE_CONFIG'])\n",
    "detection_model = model_builder.build(model_config=configs['model'], is_training=False)\n",
    "\n",
    "# Restore checkpoint\n",
    "ckpt = tf.compat.v2.train.Checkpoint(model=detection_model)\n",
    "ckpt.restore(os.path.join(paths['CHECKPOINT_PATH'], 'ckpt-3')).expect_partial()\n",
    "\n",
    "@tf.function\n",
    "def detect_fn(image):\n",
    "    image, shapes = detection_model.preprocess(image)\n",
    "    prediction_dict = detection_model.predict(image, shapes)\n",
    "    detections = detection_model.postprocess(prediction_dict, shapes)\n",
    "    return detections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Detect Mask on Webcam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: opencv-python-headless 4.5.5.62\n",
      "Uninstalling opencv-python-headless-4.5.5.62:\n",
      "  Successfully uninstalled opencv-python-headless-4.5.5.62\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall opencv-python-headless -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 \n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_index = label_map_util.create_category_index_from_labelmap(files['LABELMAP'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'out' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-7c2dd006ae97>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdestroyAllWindows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0mcap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdestroyAllWindows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'out' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "cap = cv2.VideoCapture(\"/home/elif/Documents/my_virtual_env/TFODCourse/BitirmeTezi/video.mov\" ) #test video url\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "while cap.isOpened(): \n",
    "    ret, frame = cap.read()\n",
    "    image_np = np.array(frame)\n",
    "    \n",
    "    input_tensor = tf.convert_to_tensor(np.expand_dims(image_np, 0), dtype=tf.float32)\n",
    "    detections = detect_fn(input_tensor)\n",
    "    \n",
    "    num_detections = int(detections.pop('num_detections'))\n",
    "    detections = {key: value[0, :num_detections].numpy()\n",
    "                  for key, value in detections.items()}\n",
    "    detections['num_detections'] = num_detections\n",
    "\n",
    "    # detection_classes should be ints.\n",
    "    detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n",
    "    # print(detections['detection_class_entities'], detections['detection_boxes'])\n",
    "    label_id_offset = 1\n",
    "    image_np_with_detections = image_np.copy()\n",
    "\n",
    "    viz_utils.visualize_boxes_and_labels_on_image_array(\n",
    "                image_np_with_detections,\n",
    "                detections['detection_boxes'],\n",
    "                detections['detection_classes']+label_id_offset,\n",
    "                detections['detection_scores'],\n",
    "                category_index,\n",
    "                use_normalized_coordinates=True,\n",
    "                max_boxes_to_draw=5,\n",
    "                min_score_thresh=.8,\n",
    "                agnostic_mode=False)\n",
    "\n",
    "    cv2.imshow('object detection',  cv2.resize(image_np_with_detections, (800, 600)))\n",
    "    \n",
    "    if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        break\n",
    "cv2.destroyAllWindows()\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Freezing Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "FREEZE_SCRIPT = os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection', 'exporter_main_v2.py ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "command = \"python {} --input_type=image_tensor --pipeline_config_path={} --trained_checkpoint_dir={} --output_directory={}\".format(FREEZE_SCRIPT ,files['PIPELINE_CONFIG'], paths['CHECKPOINT_PATH'], paths['OUTPUT_PATH'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python Tensorflow/models/research/object_detection/exporter_main_v2.py  --input_type=image_tensor --pipeline_config_path=Tensorflow/workspace/models/my_ssd_mobnet/pipeline.config --trained_checkpoint_dir=Tensorflow/workspace/models/my_ssd_mobnet --output_directory=Tensorflow/workspace/models/my_ssd_mobnet/export\n"
     ]
    }
   ],
   "source": [
    "print(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"Tensorflow/models/research/object_detection/exporter_main_v2.py\", line 100, in <module>\n",
      "    from absl import app\n",
      "ImportError: No module named absl\n"
     ]
    }
   ],
   "source": [
    "!{command}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting tensorflowjs\n",
      "  Downloading tensorflowjs-3.13.0-py3-none-any.whl (77 kB)\n",
      "     |ââââââââââââââââââââââââââââââââ| 77 kB 95 kB/s             \n",
      "\u001b[?25hRequirement already satisfied: tensorflow<3,>=2.1.0 in /home/elif/.local/lib/python3.6/site-packages (from tensorflowjs) (2.6.2)\n",
      "Requirement already satisfied: tensorflow-hub<0.13,>=0.7.0 in /home/elif/.local/lib/python3.6/site-packages (from tensorflowjs) (0.12.0)\n",
      "Requirement already satisfied: six<2,>=1.12.0 in /home/elif/.local/lib/python3.6/site-packages (from tensorflowjs) (1.15.0)\n",
      "Requirement already satisfied: google-pasta~=0.2 in /home/elif/.local/lib/python3.6/site-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (0.2.0)\n",
      "Requirement already satisfied: termcolor~=1.1.0 in /home/elif/.local/lib/python3.6/site-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (1.1.0)\n",
      "Requirement already satisfied: typing-extensions~=3.7.4 in /home/elif/.local/lib/python3.6/site-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (3.7.4.3)\n",
      "Requirement already satisfied: astunparse~=1.6.3 in /home/elif/.local/lib/python3.6/site-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (1.6.3)\n",
      "Requirement already satisfied: gast==0.4.0 in /home/elif/.local/lib/python3.6/site-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (0.4.0)\n",
      "Requirement already satisfied: opt-einsum~=3.3.0 in /home/elif/.local/lib/python3.6/site-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (3.3.0)\n",
      "Requirement already satisfied: keras<2.7,>=2.6.0 in /home/elif/.local/lib/python3.6/site-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (2.6.0)\n",
      "Requirement already satisfied: wrapt~=1.12.1 in /home/elif/.local/lib/python3.6/site-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (1.12.1)\n",
      "Requirement already satisfied: wheel~=0.35 in /home/elif/.local/lib/python3.6/site-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (0.37.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.37.0 in /home/elif/.local/lib/python3.6/site-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (1.41.0)\n",
      "Requirement already satisfied: absl-py~=0.10 in /home/elif/.local/lib/python3.6/site-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (0.12.0)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in /home/elif/.local/lib/python3.6/site-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (3.19.3)\n",
      "Requirement already satisfied: clang~=5.0 in /home/elif/.local/lib/python3.6/site-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (5.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.7,>=2.6.0 in /home/elif/.local/lib/python3.6/site-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (2.6.0)\n",
      "Requirement already satisfied: flatbuffers~=1.12.0 in /home/elif/.local/lib/python3.6/site-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (1.12)\n",
      "Requirement already satisfied: h5py~=3.1.0 in /home/elif/.local/lib/python3.6/site-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (3.1.0)\n",
      "Requirement already satisfied: keras-preprocessing~=1.1.2 in /home/elif/.local/lib/python3.6/site-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (1.1.2)\n",
      "Requirement already satisfied: numpy~=1.19.2 in /home/elif/.local/lib/python3.6/site-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (1.19.5)\n",
      "Requirement already satisfied: tensorboard<2.7,>=2.6.0 in /home/elif/.local/lib/python3.6/site-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (2.6.0)\n",
      "Requirement already satisfied: cached-property in /home/elif/.local/lib/python3.6/site-packages (from h5py~=3.1.0->tensorflow<3,>=2.1.0->tensorflowjs) (1.5.2)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /home/elif/.local/lib/python3.6/site-packages (from tensorboard<2.7,>=2.6.0->tensorflow<3,>=2.1.0->tensorflowjs) (0.6.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /home/elif/.local/lib/python3.6/site-packages (from tensorboard<2.7,>=2.6.0->tensorflow<3,>=2.1.0->tensorflowjs) (1.8.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /home/elif/.local/lib/python3.6/site-packages (from tensorboard<2.7,>=2.6.0->tensorflow<3,>=2.1.0->tensorflowjs) (2.0.1)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /home/elif/.local/lib/python3.6/site-packages (from tensorboard<2.7,>=2.6.0->tensorflow<3,>=2.1.0->tensorflowjs) (1.35.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/elif/.local/lib/python3.6/site-packages (from tensorboard<2.7,>=2.6.0->tensorflow<3,>=2.1.0->tensorflowjs) (3.3.4)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /home/elif/.local/lib/python3.6/site-packages (from tensorboard<2.7,>=2.6.0->tensorflow<3,>=2.1.0->tensorflowjs) (58.1.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /home/elif/.local/lib/python3.6/site-packages (from tensorboard<2.7,>=2.6.0->tensorflow<3,>=2.1.0->tensorflowjs) (0.4.6)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /home/elif/.local/lib/python3.6/site-packages (from tensorboard<2.7,>=2.6.0->tensorflow<3,>=2.1.0->tensorflowjs) (2.25.1)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /home/elif/.local/lib/python3.6/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.7,>=2.6.0->tensorflow<3,>=2.1.0->tensorflowjs) (4.2.4)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/elif/.local/lib/python3.6/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.7,>=2.6.0->tensorflow<3,>=2.1.0->tensorflowjs) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/elif/.local/lib/python3.6/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.7,>=2.6.0->tensorflow<3,>=2.1.0->tensorflowjs) (4.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/elif/.local/lib/python3.6/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.7,>=2.6.0->tensorflow<3,>=2.1.0->tensorflowjs) (1.3.0)\n",
      "Requirement already satisfied: importlib-metadata in /home/elif/.local/lib/python3.6/site-packages (from markdown>=2.6.8->tensorboard<2.7,>=2.6.0->tensorflow<3,>=2.1.0->tensorflowjs) (4.8.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/elif/.local/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard<2.7,>=2.6.0->tensorflow<3,>=2.1.0->tensorflowjs) (1.26.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/elif/.local/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard<2.7,>=2.6.0->tensorflow<3,>=2.1.0->tensorflowjs) (2021.5.30)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /home/elif/.local/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard<2.7,>=2.6.0->tensorflow<3,>=2.1.0->tensorflowjs) (4.0.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /home/elif/.local/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard<2.7,>=2.6.0->tensorflow<3,>=2.1.0->tensorflowjs) (2.10)\n",
      "Requirement already satisfied: dataclasses in /home/elif/.local/lib/python3.6/site-packages (from werkzeug>=0.11.15->tensorboard<2.7,>=2.6.0->tensorflow<3,>=2.1.0->tensorflowjs) (0.8)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /home/elif/.local/lib/python3.6/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.7,>=2.6.0->tensorflow<3,>=2.1.0->tensorflowjs) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /home/elif/.local/lib/python3.6/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.7,>=2.6.0->tensorflow<3,>=2.1.0->tensorflowjs) (3.1.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/elif/.local/lib/python3.6/site-packages (from importlib-metadata->markdown>=2.6.8->tensorboard<2.7,>=2.6.0->tensorflow<3,>=2.1.0->tensorflowjs) (3.5.1)\n",
      "Installing collected packages: tensorflowjs\n",
      "Successfully installed tensorflowjs-3.13.0\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflowjs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "command = \"tensorflowjs_converter --input_format=tf_saved_model --output_node_names='detection_boxes,detection_classes,detection_features,detection_multiclass_scores,detection_scores,num_detections,raw_detection_boxes,raw_detection_scores' --output_format=tfjs_graph_model --signature_name=serving_default {} {}\".format(os.path.join(paths['OUTPUT_PATH'], 'saved_model'), paths['TFJS_PATH'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflowjs_converter --input_format=tf_saved_model --output_node_names='detection_boxes,detection_classes,detection_features,detection_multiclass_scores,detection_scores,num_detections,raw_detection_boxes,raw_detection_scores' --output_format=tfjs_graph_model --signature_name=serving_default Tensorflow/workspace/models/my_ssd_mobnet/export/saved_model Tensorflow/workspace/models/my_ssd_mobnet/tfjsexport\n"
     ]
    }
   ],
   "source": [
    "print(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-01-28 21:26:21.855061: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-01-28 21:26:21.855152: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/elif/.local/bin/tensorflowjs_converter\", line 8, in <module>\n",
      "    sys.exit(pip_main())\n",
      "  File \"/home/elif/.local/lib/python3.6/site-packages/tensorflowjs/converters/converter.py\", line 813, in pip_main\n",
      "    main([' '.join(sys.argv[1:])])\n",
      "  File \"/home/elif/.local/lib/python3.6/site-packages/tensorflowjs/converters/converter.py\", line 817, in main\n",
      "    convert(argv[0].split(' '))\n",
      "  File \"/home/elif/.local/lib/python3.6/site-packages/tensorflowjs/converters/converter.py\", line 804, in convert\n",
      "    weight_shard_size_bytes, metadata_map)\n",
      "  File \"/home/elif/.local/lib/python3.6/site-packages/tensorflowjs/converters/converter.py\", line 533, in _dispatch_converter\n",
      "    metadata=metadata_map)\n",
      "  File \"/home/elif/.local/lib/python3.6/site-packages/tensorflowjs/converters/tf_saved_model_conversion_v2.py\", line 771, in convert_tf_saved_model\n",
      "    metadata=metadata)\n",
      "  File \"/home/elif/.local/lib/python3.6/site-packages/tensorflowjs/converters/tf_saved_model_conversion_v2.py\", line 605, in _convert_tf_saved_model\n",
      "    signature_def)\n",
      "  File \"/home/elif/.local/lib/python3.6/site-packages/tensorflowjs/converters/tf_saved_model_conversion_v2.py\", line 545, in _find_signature\n",
      "    signature_def_map = get_signature_def_map(saved_model_dir, saved_model_tags)\n",
      "  File \"/home/elif/.local/lib/python3.6/site-packages/tensorflow/python/tools/saved_model_cli.py\", line 348, in get_signature_def_map\n",
      "    meta_graph = saved_model_utils.get_meta_graph_def(saved_model_dir, tag_set)\n",
      "  File \"/home/elif/.local/lib/python3.6/site-packages/tensorflow/python/tools/saved_model_utils.py\", line 117, in get_meta_graph_def\n",
      "    saved_model = read_saved_model(saved_model_dir)\n",
      "  File \"/home/elif/.local/lib/python3.6/site-packages/tensorflow/python/tools/saved_model_utils.py\", line 55, in read_saved_model\n",
      "    raise IOError(\"SavedModel file does not exist at: %s\" % saved_model_dir)\n",
      "OSError: SavedModel file does not exist at: Tensorflow/workspace/models/my_ssd_mobnet/export/saved_model\n"
     ]
    }
   ],
   "source": [
    "!{command}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conversion TF lite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "TFLITE_SCRIPT = os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection', 'export_tflite_graph_tf2.py ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "command = \"python3 {} --pipeline_config_path={} --trained_checkpoint_dir={} --output_directory={}\".format(TFLITE_SCRIPT ,files['PIPELINE_CONFIG'], paths['CHECKPOINT_PATH'], paths['TFLITE_PATH'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python3 Tensorflow/models/research/object_detection/export_tflite_graph_tf2.py  --pipeline_config_path=Tensorflow/workspace/models/my_ssd_mobnet/pipeline.config --trained_checkpoint_dir=Tensorflow/workspace/models/my_ssd_mobnet --output_directory=Tensorflow/workspace/models/my_ssd_mobnet/tfliteexport\n"
     ]
    }
   ],
   "source": [
    "print(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-01-28 21:29:18.369981: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-01-28 21:29:18.370052: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "!{command}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FROZEN_TFLITE_PATH = os.path.join(paths['TFLITE_PATH'], 'saved_model')\n",
    "TFLITE_MODEL = os.path.join(paths['TFLITE_PATH'], 'saved_model', 'detect.tflite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "command = \"tflite_convert \\\n",
    "--saved_model_dir={} \\\n",
    "--output_file={} \\\n",
    "--input_shapes=1,300,300,3 \\\n",
    "--input_arrays=normalized_input_image_tensor \\\n",
    "--output_arrays='TFLite_Detection_PostProcess','TFLite_Detection_PostProcess:1','TFLite_Detection_PostProcess:2','TFLite_Detection_PostProcess:3' \\\n",
    "--inference_type=FLOAT \\\n",
    "--allow_custom_ops\".format(FROZEN_TFLITE_PATH, TFLITE_MODEL, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!{command}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Export Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tar -czf models.tar.gz {paths['CHECKPOINT_PATH']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
